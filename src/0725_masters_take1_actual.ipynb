{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pprint import pprint\n",
    "import z2_save_jaspar, z1_save_oligos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD JASPAR & OLIGO DATA\n",
    "jaspar = z2_save_jaspar.load_jaspar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-be7595ae187a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moligos_by_exp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutant_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exp_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     apply(lambda x:x.groupby(\"oligo\").mu.mean().sort_values(ascending=False).\\\n\u001b[0m\u001b[1;32m     15\u001b[0m           \u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"oligo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"ranksort\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode.chained_assignment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         keys, values, mutated = self.grouper.apply(f, self._selected_obj,\n\u001b[0;32m--> 707\u001b[0;31m                                                    self.axis)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 hasattr(splitter, 'fast_apply') and axis == 0):\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidApply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mfast_apply\u001b[0;34m(self, f, names)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0msdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sorted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         results, mutated = reduction.apply_frame_axis0(sdata, f, names,\n\u001b[0;32m--> 858\u001b[0;31m                                                        starts, ends)\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.apply_frame_axis0\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-be7595ae187a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moligos_by_exp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutant_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exp_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     apply(lambda x:x.groupby(\"oligo\").mu.mean().sort_values(ascending=False).\\\n\u001b[0;32m---> 15\u001b[0;31m           \u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"oligo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"ranksort\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         ranksort).unstack(level=0).rename(lambda x: x+\"_rank\",axis = \"columns\")\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4144\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4146\u001b[0;31m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5802\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5803\u001b[0m         \"\"\"\n\u001b[0;32m-> 5804\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5805\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         return self.apply('copy', axes=new_axes, deep=deep,\n\u001b[0;32m--> 734\u001b[0;31m                           do_integrity_check=False)\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'where'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m     \u001b[0;31m# sort by _can_consolidate, dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1893\u001b[0;31m     \u001b[0mgkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1894\u001b[0m     \u001b[0mgrouper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "oligos, oligos_by_exp_some,oligos_by_exp = z1_save_oligos.load_oligos()\n",
    "oligos_by_exp = oligos_by_exp.filter(regex='^(?!exp|\\\\.).*')\n",
    "oligos_by_exp[\"exp_nm\"] = oligos_by_exp.index.get_level_values(\"exp\").to_series().apply(lambda x:re.compile('(.*)_BR').search(x).groups()[0]).values\n",
    "oligos_by_exp = oligos_by_exp.reset_index()\n",
    "\n",
    "\n",
    "oligos_by_exp[\"exp_ct\"] = oligos_by_exp.exp_nm.apply(lambda x:re.compile(\"(U2OS|DLD1|HCT116)\").search(x).groups()[0])\n",
    "oligos_by_exp[\"exp_type\"] = oligos_by_exp.exp_nm.apply(lambda x:\"U2OS_NFKB\" if \"NFKB\" in x \n",
    "                                                     else (\"HCT116_GEM\") if \"Gem\" in x\n",
    "                                                     else re.compile(\"(U2OS|DLD1|HCT116)\").search(x).groups()[0]+\"_WT\")\n",
    "\n",
    "ranks = oligos_by_exp.loc[lambda x:x.mutant_num == 0].groupby(\"exp_type\").\\\n",
    "    apply(lambda x:x.groupby(\"oligo\").mu.mean().sort_values(ascending=False).\\\n",
    "          reset_index().reset_index().set_index(\"oligo\").\\\n",
    "        rename({\"index\":\"ranksort\"},axis=\"columns\").\\\n",
    "        ranksort).unstack(level=0).rename(lambda x: x+\"_rank\",axis = \"columns\")\n",
    "oligos_by_exp = oligos_by_exp.join(ranks, on=\"oligo\")\n",
    "\n",
    "obe = oligos_by_exp\n",
    "\n",
    "#LOADS MOTIF DATA\n",
    "motif_oligos_data = pd.read_csv(\"../out/0722_motif_oligos_data.csv\")\n",
    "\n",
    "motif_oligos_data =  motif_oligos_data.join(jaspar[[\"threshold_patser\"]],on=\"jaspar_id\")\n",
    "motif_oligos_data[\"affine_score\"] = motif_oligos_data.score - motif_oligos_data.threshold_patser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ranks_by_rep = oligos_by_exp.loc[lambda x:x.mutant_num == 0].groupby([\"exp_type\",\"rep\"]).\\\n",
    "    apply(lambda x:x.groupby(\"oligo\").mu.mean().sort_values(ascending=False).\\\n",
    "          reset_index().reset_index().set_index(\"oligo\").\\\n",
    "        rename({\"index\":\"ranksort\"},axis=\"columns\").\\\n",
    "        ranksort).unstack(level=0).rename(lambda x: x+\"_rank\",axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obe_w_repchanges = oligos_by_exp.join(\n",
    "    (ranks_by_rep.loc[1] - ranks_by_rep.loc[2]).rename(lambda x:x+\"_repchange\",axis =\"columns\")\n",
    "    ,on=\"oligo\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = pd.read_csv(\"../out/0729_intervals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_score_threshold = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDENTIFICATION AND DESCRIPTION OF HIGHLY EXPRESSED ENHANCER CANDIDATES IN MULTIPLE CELL TYPES ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Where are the promoters/enhancers (STARR-Seq peaks) as defined by this assay for this data in an overall pool? ####  \n",
    "In the aggregate pooled data, on average [n_tx_mean] transcripts are identified for [n_bcs_total] barcodes (n_bcs_per_oligos. The number of transcripts can be counted per barcode, giving a number for the expression rate of the that barcode which is comparable between [SEE APPENDIX A, TRANSCRIPT COUNTING] barcoded plasmids in all of our pooled sequencing. We call this transcription rate “μ” the pooled expression of a given oligo, which can be defined on a per-experiment or pooled basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint({\n",
    "    \"n_tx_mean\":oligos.n_transcripts.mean(),\n",
    "    \"n_bcs_total\":oligos.n_bcs.sum(),\n",
    "    \"n_bcs_avg\":oligos.n_bcs.mean(),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering μ over all oligo start positions, we observe ~4-5 variants of each oligo and average this quantity together to define an average expression level. Considering all such oligo-averaged expression levels, we can define peaks of expression, or putative enhancer sequences. Going forward, we define the top 5% of oligo positions by location as potential enhancer sequences “POOL-activators”. A total of [POOL_activator_len] positions of 2000 are captured by this method and defined as pooled enhancers. Likewise, the bottom 5% “POOL-repressors” of oligos by expression are split into a separate group and identified as repressors, whereas the bottom 50%of oligos are identified and described as the null background “POOL-null”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_oligos = oligos.loc[lambda x: x.mutant_num ==0]\n",
    "POOL_activators = wt_oligos.loc[lambda x: x.mu > x.mu.quantile(.95)]\n",
    "POOL_repressors = wt_oligos.loc[lambda x: x.mu < x.mu.quantile(.05)]\n",
    "POOL_null = wt_oligos.loc[lambda x: x.mu < x.mu.quantile(.5)]\n",
    "\n",
    "print({\n",
    "    \"POOL_activator_len\": len(POOL_activators),\n",
    "    \"POOL_repressor_len\": len(POOL_repressors),\n",
    "    \"POOL_null_len\": len(POOL_null),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second performing the same analysis as above, we identified a set of 5% expressed oligos, repressed oligos, and null / negative control oligos for each replicate of each experiment “{EXP_N}-activators” / “{EXP_N}-repressors”. For each experiment, we then take an intersection of the activators, repressors, and null negative control oligos observed in the two replicates of each experiment, finding that on average 67% of these oligos are observed in both replicates over all experiments. Looking at each experiment individually, the U2OS and DLD1 cell types have replicable discovery rates of 79% and 67% respectively, with U2OS cell-type having the highest replicability overall We find that activators are overall more replicable than repressors, which is as expected based upon the distribution of log scores for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_REP_activators = oligos_by_exp.loc[lambda x:x.mutant_num==0].groupby(\"exp\").apply(lambda x: x.loc[x.mu > x.mu.quantile(.95)])\n",
    "EXP_REP_repressors = oligos_by_exp.loc[lambda x:x.mutant_num==0].groupby(\"exp\").apply(lambda x: x.loc[x.mu < x.mu.quantile(.05)])\n",
    "EXP_REP_null = oligos_by_exp.loc[lambda x:x.mutant_num==0].groupby(\"exp\").apply(lambda x: x.loc[x.mu < x.mu.quantile(.5)])\n",
    "\n",
    "EXP_activator_oligos = EXP_REP_activators.groupby(\"exp_nm\").apply(lambda g1:g1.loc[g1.oligo.isin(g1.set_index(\"rep\").loc[1].oligo) & g1.oligo.isin(g1.set_index(\"rep\").loc[2].oligo)])\n",
    "EXP_repressor_oligos = EXP_REP_repressors.groupby(\"exp_nm\").apply(lambda g1:g1.loc[g1.oligo.isin(g1.set_index(\"rep\").loc[1].oligo) & g1.oligo.isin(g1.set_index(\"rep\").loc[2].oligo)])\n",
    "EXP_null_oligos = EXP_REP_null.groupby(\"exp_nm\").apply(lambda g1:g1.loc[g1.oligo.isin(g1.set_index(\"rep\").loc[1].oligo) & g1.oligo.isin(g1.set_index(\"rep\").loc[2].oligo)])\n",
    "\n",
    "EXP_activator_rep_rate =  EXP_activator_oligos.groupby(level=\"exp_nm\").apply(lambda x:x.oligo.nunique()) / EXP_REP_activators.groupby(\"exp_nm\").apply(lambda x:x.groupby(\"rep\").oligo.nunique().mean())\n",
    "EXP_repressor_rep_rate =  EXP_repressor_oligos.groupby(level=\"exp_nm\").apply(lambda x:x.oligo.nunique()) / EXP_REP_repressors.groupby(\"exp_nm\").apply(lambda x:x.groupby(\"rep\").oligo.nunique().mean())\n",
    "EXP_null_rep_rate =  EXP_null_oligos.groupby(level=\"exp_nm\").apply(lambda x:x.oligo.nunique()) / EXP_REP_null.groupby(\"exp_nm\").apply(lambda x:x.groupby(\"rep\").oligo.nunique().mean())\n",
    "#EXP_repressor_rep_rate =  EXP_repressor_oligos.groupby(level=\"exp_nm\").reset_index(\"oligo\").oligo.nunique().mean() / EXP_REP_repressors.groupby(\"exp_nm\").reset_index(\"oligo\").oligo.nunique()\n",
    "\n",
    "DLD1_activator_rediscovery_rate = EXP_activator_rep_rate.loc[\"DLD1_WT\"]\n",
    "U2OS_activator_rediscovery_rate = EXP_activator_rep_rate.loc[\"U2OS_WT\"]\n",
    "MAX_activator_rediscovery_celltype = EXP_activator_rep_rate.idxmax()\n",
    "\n",
    "pprint({\n",
    "    \"EXP_activators_mean_len\":EXP_activator_oligos.groupby(level=\"exp_nm\").oligo.nunique().mean(),\n",
    "    \"EXP_repressors_mean_len\":EXP_repressor_oligos.groupby(level=\"exp_nm\").oligo.nunique().mean(),\n",
    "    \"EXP_null_mean_len\":EXP_null_oligos.groupby(level=\"exp_nm\").oligo.nunique().mean(),\n",
    "    \"EXP_repressor__mean_rep_rate\":EXP_repressor_rep_rate.mean(),\n",
    "    \"EXP_activator_mean_rep_rate\":EXP_activator_rep_rate.mean(),\n",
    "    \"EXP_null_mean_rep_rate\":EXP_null_rep_rate.mean(),\n",
    "    \"U2OS_activator_rediscovery_rate\":U2OS_activator_rediscovery_rate,\n",
    "    \"DLD1_activator_rediscovery_rate\":DLD1_activator_rediscovery_rate,\n",
    "    \"MAX_activator_rediscovery_celltype\":MAX_activator_rediscovery_celltype,\n",
    "    \"EXP_activator_rep_rate\": EXP_activator_rep_rate,\n",
    "})\n",
    "\n",
    "\n",
    "plt.gcf().set_size_inches(6,4)\n",
    "ax = plt.gca()\n",
    "plt.hist([(np.log2(g.mu) - np.log2(g.mu.mean())).rename(k) for k, g in oligos_by_exp.groupby(\"exp_nm\")])\n",
    "\n",
    "ax.set_title(\"histogram of normalized log2 expression rates by experiment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing that APOBEC is expressed in DLD1 and U2OS cells, we defined a further set of activators defined as “APOBEC-on” enhancers, consisting of those enhancers which were identified both in the DLD1 replicates and the U2OS replicates, this set had {100} elements. Lastly, observing that APOBEC is not expressed in HCT116 cells, we defined a final set of activators of interest, consisting of {59} possible transcription activators which exhibited high transcription in U2OS and DLD1 cells (ie, in the APOBEC-on enhancers), but not in HCT116 cells. These were called “APOBEC-exclusive” candidate enhancer regions. Observing that U2OS expression tended to differ greatly with DLD1 expression, and U2OS expression was overall higher, we also investigated another set, \"U2OS-on\", with U2OS-identified enhancers, excluding those which were detected in HCT116 peaks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "APOBEC_on_oligo_ids = set(EXP_activator_oligos.loc[\"DLD1_WT\"].oligo).intersection(EXP_activator_oligos.loc[\"U2OS_WT\"].oligo)\n",
    "APOBEC_sometimes_oligo_ids = set(EXP_activator_oligos.loc[\"DLD1_WT\"].oligo).union(EXP_activator_oligos.loc[\"U2OS_WT\"].oligo)\n",
    "ABon_ids = APOBEC_on_oligo_ids\n",
    "ABst_ids = APOBEC_sometimes_oligo_ids\n",
    "\n",
    "\n",
    "APOBEC_exclusive_oligo_ids =APOBEC_on_oligo_ids.difference(EXP_activator_oligos.loc[\"HCT116_WT\"].oligo)\n",
    "U2OS_on_oligo_ids = set(EXP_activator_oligos.loc[\"U2OS_WT\"].oligo)\n",
    "\n",
    "\n",
    "ABex_ids = APOBEC_exclusive_oligo_ids \n",
    "U2on_ids = U2OS_on_oligo_ids\n",
    "U2ex_ids = set(U2OS_on_oligo_ids).difference(EXP_activator_oligos.loc[\"HCT116_WT\"].oligo)\n",
    "\n",
    "ALLen_ids = set(EXP_activator_oligos.oligo)\n",
    "WTst_ids =APOBEC_sometimes_oligo_ids.union(EXP_activator_oligos.loc[\"HCT116_WT\"].oligo)\n",
    "\n",
    "\n",
    "AB_differential_enhancer_ids = obe.loc[lambda x: x.oligo.isin(ABst_ids)].\\\n",
    "        loc[lambda df:abs(df.U2OS_WT_rank -df.DLD1_WT_rank) > 100].oligo.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oligo_exp_activator_matrix = pd.Series(1, index =EXP_activator_oligos.oligo.to_frame().reset_index().set_index([\"exp_nm\",\"oligo\"]).index).loc[lambda df: ~df.index.duplicated(keep='first') ].unstack(\"exp_nm\").fillna(0)\n",
    "oligo_exp_activator_matrix = oligo_exp_activator_matrix.append( [ pd.Series(0, index = oligo_exp_activator_matrix.columns).rename(o) for o in [e for e in obe.oligo.unique() if e not in oligo_exp_activator_matrix.index] ])\n",
    "correlations = oligo_exp_activator_matrix.corr()\n",
    "for nm in correlations.columns: correlations.loc[nm,nm] = 0\n",
    "\n",
    "intersection_grid = np.array([[np.sum(oligo_exp_activator_matrix[c1].values * oligo_exp_activator_matrix[c2].values)\n",
    "     for c1 in oligo_exp_activator_matrix.columns ]\n",
    "     for c2 in oligo_exp_activator_matrix.columns])\n",
    "\n",
    "sns.clustermap((oligo_exp_activator_matrix.loc[oligo_exp_activator_matrix.sum(axis=1) >0].filter(regex=\".*WT.*\" )),figsize=(3,3))\n",
    "#sns.clustermap(oligo_exp_activator_matrix.filter(regex=\".*WT.*\" ).T.filter(regex=\".*WT.*\" ),figsize=(3,3))\n",
    "sns.clustermap((oligo_exp_activator_matrix.loc[oligo_exp_activator_matrix.sum(axis=1) >0]),figsize=(3,3))\n",
    "\n",
    "f,subs = plt.subplots(1,2)\n",
    "f.set_size_inches(9,5)\n",
    "\n",
    "plt.sca(subs[0])\n",
    "sns.lineplot(x = \"U2OS_WT_rank\", y = \"mu\",  hue = \"exp_nm\", data = oligos_by_exp.loc[lambda x: x.oligo.isin(EXP_activator_oligos.loc[\"U2OS_WT\"].oligo)])\n",
    "plt.legend(loc=[0,1.1])\n",
    "\n",
    "plt.sca(subs[1])\n",
    "sns.lineplot(x = \"DLD1_WT_rank\", y = \"mu\",  hue = \"exp_nm\", data = oligos_by_exp.loc[lambda x: x.oligo.isin(EXP_activator_oligos.loc[\"DLD1_WT\"].oligo)],legend=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do enhancer regions exhibit differential activity in the cell types under study? ####\n",
    "We had previously identified separate groups of top5% enhancers in each cell type under study. Furthermore, we observed that the groups of top5% enhancers were different for each of the cell types. To define APOBEC-on activators, we took an intersection of the top5% enhancers. To study differential expression in these cell types, we defined a new set of APOBEC-sometimes enhancer regions consisting of the union of top5% enhancer oligos in each of these (ABst) experiments. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There were {100} total enhancer locations in the ABst set. For each enhancer, we examined the descending rank-sorted order of that enhancer in the experimental data for that locus, assigning a number equal to the absolute value of that rank sort-order difference in each set to each of the APOBEC-somstetimes enhancer regions. Looking at the full set of APOBEC-sometimes enhancer regions, we found a mean ranksort discrepancy of {248} between the two data sets. To quantify significance of this number, we also computed the mean ranksort discrepancy of the APOBEC-sometimes enhancers in each of the two experimental replicates of DLD1 and U2OS. We found that the average absolute ranksort differential of APOBEC-sometimes enhancer candidates was [111] and [49] in the DLD1 and U2OS replicates respectively, with an overall mean of [250]. Importantly, we found that amongst the U2OSon and DLD1on oligos, the average rank changes between replicates was 7.63 and 12.75 respectively, leading us to conclude that for the most expressed oligos, the expression rank change provided an internally consistent number.\n",
    "\n",
    "Equipped with this measure, we set a threshold of rank expression change of 100 ranks and observed that 47 of the ABst potential enahncers changed in rank by 100 or more between the two experiments. We called these “APOBEC-differential-enhancers”, and noted that these 47 oligos were candidates for cell-type specific differential activation of APOBEC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abst_U2OSNKFB_U2OS_WT_rankdiff = obe.loc[lambda x: x.oligo.isin(ABst_ids)].\\\n",
    "        apply(lambda df:abs(df.U2OS_WT_rank -df.U2OS_NFKB_rank),axis=1)\n",
    "\n",
    "all_U2OSNKFB_U2OS_WT_rankdiff = obe.loc[lambda x:  x.mutant_num == 0].\\\n",
    "        apply(lambda df:abs(df.U2OS_WT_rank -df.U2OS_NFKB_rank),axis=1)\n",
    "\n",
    "abst_dld1_U2OS_WT_rankdiff = obe.loc[lambda x: x.oligo.isin(ABst_ids)].\\\n",
    "        apply(lambda df:abs(df.U2OS_WT_rank -df.DLD1_WT_rank),axis=1)\n",
    "\n",
    "all_dld1_U2OS_WT_rankdiff = obe.loc[lambda x: x.mutant_num == 0].\\\n",
    "        apply(lambda df:abs(df.U2OS_WT_rank -df.DLD1_WT_rank),axis=1)\n",
    "\n",
    "AB_differential_enhancer_ids = obe.loc[lambda x: x.oligo.isin(ABst_ids)].\\\n",
    "        loc[lambda df:abs(df.U2OS_WT_rank -df.DLD1_WT_rank) > 100].oligo.unique()\n",
    "\n",
    "print(f\"\"\" mean difference between rank sorts in U2OS vs DLD1 cells over--\n",
    "   ABST oligos: ({abst_dld1_U2OS_WT_rankdiff.mean():.2f})  \n",
    "   ALL wt oligos: ({all_dld1_U2OS_WT_rankdiff.mean():.2f})\n",
    "\n",
    "Looking at only U2OS cell lines in NFKB-ko and NFKB designs, we find that the differences are reduced\n",
    "   ABST oligos: ({abst_U2OSNKFB_U2OS_WT_rankdiff.mean():.2f})  \n",
    "   ALL oligos: ({all_U2OSNKFB_U2OS_WT_rankdiff.mean():.2f})  \n",
    "\n",
    "\n",
    "... and furthermore, that the rank change difference of expression levels amongst ABst expressed oligos is\n",
    "reduced compared to the rank change difference between all oligos. In order to quantify the base level of\n",
    "noise in rank fold change amongst all oligos, we looked at the average fold change difference between replicates,\n",
    "finding that the overall change in expression ranks for \n",
    "\n",
    "ALL OLIGOS (U2OS) {obe_w_repchanges[\"U2OS_WT_rank_repchange\"].abs().mean():.2f}\n",
    "ABST OLIGOS (U2OS) {obe_w_repchanges.loc[lambda x: x.oligo.isin(ABst_ids)][\"U2OS_WT_rank_repchange\"].abs().mean():.2f}\n",
    "ABST OLIGOS (U2OS) {obe_w_repchanges.loc[lambda x: x.oligo.isin(U2on_ids)][\"U2OS_WT_rank_repchange\"].abs().mean():.2f}\n",
    "\n",
    "\n",
    "ALL OLIGOS (DLD1) {obe_w_repchanges[\"DLD1_WT_rank_repchange\"].abs().mean():.2f}\n",
    "ABST OLIGOS (DLD1) {obe_w_repchanges.loc[lambda x: x.oligo.isin(ABst_ids)][\"DLD1_WT_rank_repchange\"].abs().mean():.2f}\n",
    "ABST OLIGOS (DLD1) {obe_w_repchanges.loc[lambda x: x.oligo.isin(EXP_activator_oligos.loc[\"DLD1_WT\"].oligo)][\"DLD1_WT_rank_repchange\"].abs().mean():.2f}\n",
    "\n",
    "Number of \"APOBEC-differentialy-expressed\" oligos:\n",
    "    {len(AB_differential_enhancer_ids)} \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from this measure of differential expression in wild-type cells that were highly expressive of APOBEC, we sought to apply the same measure to quantification of differential expression between the APOBEC-expressing cell lines and the HCT116 cell type which does not natively express APOBEC. Defining an inclusive set of enhancers, WILDTYPE-activators with [XXX] members, consisting of the top5% enhancers from DLD1, HCT116, and U2OS, we looked at differential expression, computed between all 3x3 cell types for each of these enhancers. We were also curious to see how differential expression of the bot5% would vary between these three cell types and therefore defined the set WILDTYPE-repressors and computed the same score, using all 3x3 comparisons.\n",
    "\n",
    "Using the same definitions above, we computed average and std deviation of ranksort discrepancies for activators ( [XXX]mean, [XXX]stddev ) and repressors  ( [XXX]mean, [XXX]stddev )  individually and identified as differentially expressed all those oligos which crossed the threshold of mean + 1 std discrepancy change. By this measure, we found that [XXX] / ([XXX]) oligos were differentially expressed between either DLD1 / (U2OS) and HCT116 cells respectively. We called their intersection, the “APOBEC-on-enhancers” (XXX regions). Comparing the set of oligos previously identified as in the DLD1 and U2OS sets but not in HCT116 cells (“ABOPEC-exclusive” oligos), we found that [XXX]% of APOBEC-exclusive oligos were found in this set of differentially expressed oligos, confirming the internal consistency of these two measures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obe_wtst = obe.loc[lambda x: x.oligo.isin(WTst_ids) ]\n",
    "celltypes = pd.Series([\"DLD1_WT\",\"U2OS_WT\",\"HCT116_WT\"], index = [\"DLD1_WT\",\"U2OS_WT\",\"HCT116_WT\"])\n",
    "exptypes = pd.Series(obe.exp_type.unique(), index = obe.exp_type.unique())\n",
    "\n",
    "enhancer_intersection_sizes = celltypes.apply(lambda x: celltypes.apply(lambda y:len(\n",
    "    set(EXP_activator_oligos.loc[x].oligo.unique()).intersection(\n",
    "    set(EXP_activator_oligos.loc[y].oligo.unique())))))\n",
    "\n",
    "WTst_differential_expression_count = \\\n",
    "exptypes.apply(lambda ct1: \n",
    "        exptypes.apply(lambda ct2:\n",
    "            len(set(obe_wtst.loc[lambda x:(abs(x[ct1 + \"_rank\"]  - x[ct2+\"_rank\"])) > 100].oligo.unique()))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "number of oligos highly expressed in at least one of: DLD1, U2OS, HCT116 WILDTYPE CELLS: {len(WTst_ids)}\n",
    "\n",
    "Looking at the number of differentially expressed transcripts by delta-rank > 100 metric in each cell type, we\n",
    "get:\n",
    "   U2OS --> DLD1 {WTst_differential_expression_count.loc[\"U2OS_WT\",\"DLD1_WT\"]}\n",
    "   U2OS --> HTC116 {WTst_differential_expression_count.loc[\"U2OS_WT\",\"HCT116_WT\"]}\n",
    "   DLD1 --> HCT116 {WTst_differential_expression_count.loc[\"DLD1_WT\",\"HCT116_WT\"]}\n",
    "   \n",
    "Counts of differentially expressed transcripts in each cell type.\n",
    "\n",
    "Looking at experiment type changes, we find \n",
    "   U2OS_WT --> U2OS_NFKB_KO {WTst_differential_expression_count.loc[\"U2OS_WT\",\"U2OS_NFKB\"]}\n",
    "   HCT116_WT --> HCT116_GEM {WTst_differential_expression_count.loc[\"HCT116_WT\",\"HCT116_GEM\"]}\n",
    "      \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do enhancer regions exhibit differential activity in the cell types under study? ###\n",
    "We had previously identified separate groups of top5% enhancers in each cell type under study. Furthermore, we observed that the groups of top5% enhancers were different for each of the cell types. To define APOBEC-on activators, we took an intersection of the top5% enhancers. To study differential expression in these cell types, we defined a new set of APOBEC-sometimes enhancer regions consisting of the union of top5% enhancer oligos in each of these experiments. \n",
    "\n",
    "There were [XXX] total enhancer locations in this set. For each enhancer, we examined the descending rank-sorted order of that enhancer in the experimental data for that locus, assigning a number equal to the absolute value of that rank sort-order difference in each set to each of the APOBEC-somstetimes enhancer regions. Looking at the full set of APOBEC-sometimes enhancer regions, we found a mean ranksort discrepancy of [XXX] between the two data sets. To quantify significance of this number, we also computed the mean ranksort discrepancy of the APOBEC-sometimes enhancers in each of the two experimental replicates of DLD1 and U2OS. We found that the average absolute ranksort differential of APOBEC-sometimes enhancer candidates was [XXX] and [XXX] in the DLD1 and U2OS replicates respectively, with an overall mean of [XXX] and overall standard deviation of [XXX]. We set a threshold of [XXX], which was the mean discrepancy + 1 STD as the ranksort discrepancy to define a given enhancer oligo as differentially activating between the two cell types and found that amongst the [XXX] oligos in APOBEC-sometimes, [XXX] ([XXX]%) “APOBEC-differential-activators”, were differentially expressed by this measure.\n",
    "\n",
    "Starting from this measure of differential expression in wild-type cells that were highly expressive of APOBEC, we sought to apply the same measure to quantification of differential expression between the APOBEC-expressing cell lines and the HCT116 cell type which does not natively express APOBEC. Defining an inclusive set of enhancers, WILDTYPE-activators with [XXX] members, consisting of the top5% enhancers from DLD1, HCT116, and U2OS, we looked at differential expression, computed between all 3x3 cell types for each of these enhancers. We were also curious to see how differential expression of the bot5% would vary between these three cell types and therefore defined the set WILDTYPE-repressors and computed the same score, using all 3x3 comparisons.\n",
    "\n",
    "Using the same definitions above, we computed average and std deviation of ranksort discrepancies for activators ( [XXX]mean, [XXX]stddev ) and repressors  ( [XXX]mean, [XXX]stddev )  individually and identified as differentially expressed all those oligos which crossed the threshold of mean + 1 std discrepancy change. By this measure, we found that [XXX] / ([XXX]) oligos were differentially expressed between either DLD1 / (U2OS) and HCT116 cells respectively. We called their intersection, the “APOBEC-on-enhancers” (XXX regions). Comparing the set of oligos previously identified as in the DLD1 and U2OS sets but not in HCT116 cells (“ABOPEC-exclusive” oligos), we found that [XXX]% of APOBEC-exclusive oligos were found in this set of differentially expressed oligos, confirming the internal consistency of these two measures. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffex = exptypes.apply(lambda ct1: \n",
    "        exptypes.apply(lambda ct2:\n",
    "            obe_wtst.loc[lambda x:(x[ct1 + \"_rank\"]  - x[ct2+\"_rank\"]) > 100].oligo.unique())).stack()\\\n",
    "    .groupby(level=[0,1]).apply(lambda x:pd.Series([e for i,e in enumerate(x.values[0])]))\n",
    "\n",
    "diffex = diffex.rename(\"oligo\").reset_index(level=2,drop=True)\n",
    "diffex = diffex.rename_axis([\"expressed\",\"unexpressed\"]).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZERO AREA FILTERING #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obe = oligos_by_exp.reset_index().loc[lambda x:x.mutant_num<5].groupby([\"starts\",\"mutant_num\",\"exp_type\"]).mu.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = pd.concat(\n",
    "    [all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([(df.values[ofs:ofs+4,:] * (\n",
    "        np.concatenate([\n",
    "            (np.zeros((4,1))+1),\n",
    "            np.fliplr(1 - np.diag([1,1,1,1]))],\n",
    "        axis=1))\n",
    "               ).sum()  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"allothers\") / 16,\n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([(df.values[ofs:ofs+4,:] * (\n",
    "        np.concatenate([\n",
    "            (np.zeros((4,1))),\n",
    "            np.fliplr( np.diag([1,1,1,1]))],\n",
    "        axis=1))\n",
    "               ).sum()  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"onlyablations\") / 4,\n",
    "     \n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([\n",
    "        (df.values[ofs:ofs+5,:][np.nonzero(\n",
    "                       np.array([[0,0,0,0,1],\n",
    "                       [0,0,0,1,1],\n",
    "                       [0,0,1,1,0],\n",
    "                       [0,1,1,0,0],\n",
    "                       [0,1,0,0,0]]))]\n",
    "               ).sum()   \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"allothers2\") / 17,\n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([np.std(df.values[ofs:ofs+4,:][np.nonzero (\n",
    "        np.concatenate([\n",
    "            (np.zeros((4,1))+1),\n",
    "            np.fliplr(1 - np.diag([1,1,1,1]))],\n",
    "        axis=1))\n",
    "                                             ])\n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"allothersstd\"),\n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([np.std(df.values[ofs:ofs+4,:])  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"std\"),\n",
    "         all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([\n",
    "        (df.values[ofs:ofs+5,:][np.nonzero(\n",
    "                       np.array([[0,0,0,0,1],\n",
    "                       [0,0,0,1,1],\n",
    "                       [0,0,1,1,0],\n",
    "                       [0,1,1,0,0],\n",
    "                       [0,1,0,0,0]]))]\n",
    "               ).sum()  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"onlyablations2\") / 8,\n",
    "          all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([(df.values[ofs:ofs+4,:] * (\n",
    "        np.concatenate([\n",
    "            (np.zeros((4,1))),\n",
    "            np.fliplr(1 - np.diag([1,1,1,1]))],\n",
    "        axis=1))\n",
    "               ).sum()  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"othermutants\") / 12,\n",
    "     \n",
    "          all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([(df.values[ofs:ofs+4,:] * (\n",
    "        np.concatenate([\n",
    "            (np.zeros((4,1))+1),\n",
    "            np.fliplr(0* np.diag([1,1,1,1]))],\n",
    "        axis=1))\n",
    "               ).sum()  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"onlywildtype\") / 4,\n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(lambda df:\n",
    "                                                \n",
    "       pd.Series([ks_2samp( df.values[ofs:ofs+4,:][np.nonzero(   np.concatenate([\n",
    "            (np.zeros((4,1))+1),\n",
    "            np.fliplr(1-np.diag([1,1,1,1]))],\n",
    "        axis=1))] ,\n",
    "                 df.values[ofs:ofs+4,:][np.nonzero(  np.concatenate([\n",
    "            (np.zeros((4,1))+0),\n",
    "            np.fliplr(np.diag([1,1,1,1]))],\n",
    "        axis=1))])[1]\n",
    "          for ofs in range(len(df.values) - 4)],index = df.index[4:])).rename(\"ks_pval\"),\n",
    "     \n",
    "          all_obe.unstack(level=1).groupby(level=1).apply(lambda df:\n",
    "                                                \n",
    "       pd.Series([ks_2samp( df.values[ofs:ofs+5,:][np.nonzero(\n",
    "                       np.array([[0,0,0,0,1],\n",
    "                       [0,0,0,1,1],\n",
    "                       [0,0,1,1,0],\n",
    "                       [0,1,1,0,0],\n",
    "                       [0,1,0,0,0]]))],\n",
    "           df.values[ofs:ofs+5,:][np.nonzero(\n",
    "                       1- np.array([[0,0,0,0,1],\n",
    "                       [0,0,0,1,1],\n",
    "                       [0,0,1,1,0],\n",
    "                       [0,1,1,0,0],\n",
    "                       [0,1,0,0,0]]))]\n",
    "       )[1]\n",
    "          for ofs in range(len(df.values) - 4)],index = df.index[4:])).rename(\"ks2_pval\"),\n",
    "     \n",
    "     \n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(lambda df:\n",
    "                                                \n",
    "       pd.Series([ks_2samp( df.values[ofs:ofs+4,:][np.nonzero(   np.concatenate([\n",
    "            (np.zeros((4,1))+1),\n",
    "            np.fliplr(1-np.diag([1,1,1,1]))],\n",
    "        axis=1))] ,\n",
    "                 df.values[ofs:ofs+4,:][np.nonzero(  np.concatenate([\n",
    "            (np.zeros((4,1))+0),\n",
    "            np.fliplr(np.diag([1,1,1,1]))],\n",
    "        axis=1))])[0]\n",
    "          for ofs in range(len(df.values) - 4)],index = df.index[4:])).rename(\"ks_stat\")\n",
    "    ],axis = 1).reset_index(level=2, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.index.names = [\"exp_type\",\"starts\"]\n",
    "filters[\"actual_starts\"] = filters.index.get_level_values(\"starts\") + 30\n",
    "filters = filters.reset_index(level=1, drop = True).set_index(\"actual_starts\",append=True)\n",
    "filters.index.names = [\"exp_type\",\"mutant_start_position\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters[\"mutdiff\"] = filters[\"othermutants\"] - filters[\"onlyablations\"]\n",
    "filters[\"wtdiff\"] = filters[\"onlywildtype\"] - filters[\"onlyablations\"]\\\n",
    "\n",
    "filters[\"othersdiff\"] = filters[\"allothers\"] - filters[\"onlyablations\"]\n",
    "filters[\"rank_mutdiff\"] = filters[[\"mutdiff\"]].join(\n",
    "        filters[[\"mutdiff\"]].groupby(\"mutant_start_position\").mean().reset_index().sort_values(\"mutdiff\",ascending = False).reset_index().rename_axis(\"rank\",axis=\"index\").reset_index().set_index([\"mutant_start_position\"])[\"rank\"],\n",
    "    on=\"mutant_start_position\")[\"rank\"]\n",
    "filters[\"rank_ao\"] = filters[[\"othersdiff\"]].join(\n",
    "        filters[[\"othersdiff\"]].groupby(\"mutant_start_position\").mean().reset_index().sort_values(\"othersdiff\",ascending = False).reset_index().rename_axis(\"rank\",axis=\"index\").reset_index().set_index([\"mutant_start_position\"])[\"rank\"],\n",
    "    on=\"mutant_start_position\")[\"rank\"]\n",
    "filters[\"rank_ao_dld1\"] = filters[[\"othersdiff\"]].loc[lambda x: x.index.get_level_values(0).str.contains(\"DLD\")].join(\n",
    "        filters[[\"othersdiff\"]].groupby(\"mutant_start_position\").mean().reset_index().sort_values(\"othersdiff\",ascending = False).reset_index().rename_axis(\"rank\",axis=\"index\").reset_index().set_index([\"mutant_start_position\"])[\"rank\"],\n",
    "    on=\"mutant_start_position\")[\"rank\"]\n",
    "filters[\"rank_ao_u2os\"] = filters[[\"othersdiff\"]].loc[lambda x: x.index.get_level_values(0).str.contains(\"U2OS\")].join(\n",
    "        filters[[\"othersdiff\"]].groupby(\"mutant_start_position\").mean().reset_index().sort_values(\"othersdiff\",ascending = False).reset_index().rename_axis(\"rank\",axis=\"index\").reset_index().set_index([\"mutant_start_position\"])[\"rank\"],\n",
    "    on=\"mutant_start_position\")[\"rank\"]\n",
    "filters[\"rank_ao_hct116\"] = filters[[\"othersdiff\"]].loc[lambda x: x.index.get_level_values(0).str.contains(\"HCT\")].join(\n",
    "        filters[[\"othersdiff\"]].groupby(\"mutant_start_position\").mean().reset_index().sort_values(\"othersdiff\",ascending = False).reset_index().rename_axis(\"rank\",axis=\"index\").reset_index().set_index([\"mutant_start_position\"])[\"rank\"],\n",
    "    on=\"mutant_start_position\")[\"rank\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters[\"filterchange\"] = np.max(\n",
    "    [(filters.onlyablations - filters.allothers),\n",
    "     (filters.onlyablations2 - filters.allothers2)]\n",
    ")\n",
    "filters[\"ks_1or2\"] = filters.apply(lambda x: (x.ks_pval < .05) | (x.ks2_pval < .05),axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters[\"filter_color\"] =filters.apply( lambda x: \n",
    "                                       5 if (x.ks_1or2 & x.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters[\"log_ks_pval\"] = np.log(filters.ks_pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filters.loc[filters.ks_pval < .05]), len(filters.loc[filters.ks2_pval < .05]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_hq = filters.loc[lambda x: x.ks_1or2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = \"onlyablations\",\n",
    "                y=filters.apply(lambda x:x.allothers- x.onlyablations,axis =1),size = \"allothersstd\", \n",
    "hue = filters.ks_pval.apply(lambda x: 1 if x < .05 else 0),data = filters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.jointplot(x = \"onlyablations\",\n",
    "                y=\"allothers\",\n",
    "                data = filters_hq.loc[lambda x:(x.ks_pval<.05) & (x.onlywildtype > 2.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsub = filters_hq.loc[lambda x:(x.ks_pval<.05) & (x.onlywildtype > 2.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x =\"log_ks_pval\", y=\"allothers\" , data = fsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ranking in [\"rank_ao_u2os\",\"rank_ao_dld1\",\"rank_ao_hct116\"]:\n",
    "    f = plt.figure()\n",
    "    f.set_size_inches(5,3)\n",
    "    mubar_wt_cutoffs = filters.groupby(\"exp_type\").onlywildtype.quantile(.95)\n",
    "    sns.lineplot(x=ranking, y=\"mubar\",\n",
    "                 style=\"filter_name\", \n",
    "                 hue=\"exp_type\",\n",
    "                 estimator=None,\n",
    "                 data = filters.loc[lambda x:(x[ranking]< 100) \n",
    "                                    & (x.apply(lambda y:y.onlywildtype>mubar_wt_cutoffs[y.name[0]],axis=1))]\\\n",
    "                 .reset_index()\\\n",
    "                     .melt(id_vars=[\"rank_mutdiff\",\"rank_ao\",ranking,\"mutant_start_position\",\"exp_type\"],\n",
    "                           value_vars=[\"onlyablations\",\"allothers\"],\n",
    "                           value_name=\"mubar\",\n",
    "                           var_name=\"filter_name\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ranking in [\"rank_ao_u2os\",\"rank_ao_dld1\",\"rank_ao_hct116\"]:\n",
    "    f = plt.figure()\n",
    "    f.set_size_inches(5,3)\n",
    "    mubar_wt_cutoffs = filters_hq.groupby(\"exp_type\").onlywildtype.quantile(.95)\n",
    "    sns.lineplot(x=ranking, y=\"mubar\",\n",
    "                 style=\"filter_name\", \n",
    "                 hue=\"exp_type\",\n",
    "                 estimator=None,\n",
    "                 data = filters_hq.loc[lambda x:\n",
    "                                       (x.apply(lambda y:y.onlywildtype>mubar_wt_cutoffs[y.name[0]],axis=1))]\\\n",
    "                 .reset_index()\\\n",
    "                     .melt(id_vars=[\"rank_mutdiff\",\"rank_ao\",ranking,\"mutant_start_position\",\"exp_type\"],\n",
    "                           value_vars=[\"onlyablations\",\"allothers\"],\n",
    "                           value_name=\"mubar\",\n",
    "                           var_name=\"filter_name\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHICH 30BP REGIONS PASS THE ZERO AREA FILTER & HAVE WT EXPRESSION LEVELS FALLING INTO THE TOP 5%? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals =  [.75,.85,.9,.95,.98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.groupby(\"exp_type\").onlywildtype.quantile(wt_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_hq.apply(lambda y:(1 if (y.onlywildtype > mubar_wt_cutoffs.loc[y.name[0]]) else 0),axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_hq.loc[[\"DLD1_WT\"]].apply(lambda y:(1 if (y.onlywildtype > mubar_wt_cutoffs.loc[y.name[0]]) else 0),axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "these_filters.apply(lambda y:[y.filterchange ,filter_change_cutoff.loc[y.name[0]]],axis=1)[\"HCT116_WT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "these_filters.apply(lambda y:(1 if (y.filterchange > filter_change_cutoff.loc[y.name[0]]) else 0),axis=1).groupby(level=0).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_change_cutoff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = pd.DataFrame()\n",
    "quantile_counts = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for quantile in qvals:\n",
    "    \n",
    "    these_filters = filters_hq.copy()\n",
    "    wt_quantile = quantile\n",
    "    change_quantile = quantile\n",
    "\n",
    "    #USES ALL EXPRESSION VALUES\n",
    "    mubar_wt_cutoffs = filters.groupby(\"exp_type\").onlywildtype.quantile(wt_quantile)\n",
    "    \n",
    "    #filters_hq[\"filterchange\"] = filters_hq.onlyablations - filters_hq.allothers\n",
    "    #filter_change_cutoff = filters.filterchange.groupby(\"exp_type\").quantile(change_quantile)\n",
    "    these_filters[\"filterchange\"] =  these_filters.apply(lambda x:\n",
    "                                                       np.max(np.abs([x.onlyablations - x.allothers,\n",
    "                                                               x.onlyablations2 - x.allothers2,])),axis=1)\n",
    "    filter_change_cutoff = these_filters.filterchange.groupby(\"exp_type\").quantile(change_quantile)\n",
    "\n",
    "    \n",
    "    \n",
    "    #change_filter_value = these_filters.filterchange.quantile(change_quantile)\n",
    "    #change_filter_value = 1\n",
    "    #filter_change_cutoff = these_filters.groupby(\"exp_type\").apply(lambda x:change_filter_value)\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    wt_cutoff quantile {quantile} == {mubar_wt_cutoffs}\n",
    "    change_cutoff mean quantile {quantile} == {filter_change_cutoff}\n",
    "    \"\"\")\n",
    "    these_filters[\"filterchange\"] =  these_filters.apply(lambda x:\n",
    "                                                       np.max(np.abs([x.onlyablations - x.allothers,\n",
    "                                                               x.onlyablations2 - x.allothers2,])),axis=1)\n",
    "    \n",
    "    these_filters[\"wt_filtered\"] = these_filters.apply(lambda y:(1 if (y.onlywildtype > mubar_wt_cutoffs.loc[y.name[0]]) else 0),axis=1)\n",
    "    these_filters[\"change_filtered\"] = these_filters.apply(lambda y:(1 if (y.filterchange > filter_change_cutoff.loc[y.name[0]]) else 0),axis=1)\n",
    "    these_filters[\"both_filtered\"] = these_filters.wt_filtered * these_filters.change_filtered\n",
    "\n",
    "    these_filters[\"filter_color\"] = these_filters.apply(\n",
    "        lambda x: (3 if x.both_filtered \n",
    "                   else(2 if x.change_filtered \n",
    "                        else (1 if x.wt_filtered \n",
    "                              else 0) )),axis=1)\n",
    "\n",
    "    quantiles = quantiles.append(these_filters.assign(quantile = quantile))\n",
    "    out = pd.Series([1,2,3]).apply(lambda n:(these_filters[\"filter_color\"].loc[lambda x:x>0].unstack(level=0).fillna(0) == n).sum()).assign(quantile = quantile)\n",
    "    quantile_counts =quantile_counts.append(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,subs = plt.subplots(1,quantiles[\"quantile\"].nunique())\n",
    "\n",
    "\n",
    "f.set_size_inches(10,12)\n",
    "for i,q in enumerate(sorted(quantiles[\"quantile\"].unique())):\n",
    "    plt.sca(subs[i])\n",
    "    data = quantiles.loc[lambda df:df[\"quantile\"]==q]\n",
    "    sns.heatmap( data = (data[\"filter_color\"]*(data[\"ks_pval\"]<.1)).loc[lambda x:x>0].unstack(level=0).fillna(0))\n",
    "\n",
    "    #plt.sca(subs[i*2+1])\n",
    "    #sns.heatmap(data[\"log_ks_pval\"].loc[lambda x:x<-2].unstack(level=0).fillna(0))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_scores = [1,2,3,5]\n",
    "\n",
    "qjoin_afs = pd.concat([\n",
    " pd.merge(\n",
    "    quantiles.reset_index(),\n",
    "    data.dropna(subset =[\"target_mutant_start_position\"]).loc[lambda x: x.affine_score > afs],\n",
    "    right_on=\"target_mutant_start_position\",\n",
    "    left_on=\"mutant_start_position\").assign(affine_score_threshold = afs)\n",
    "    \n",
    "    for afs in affine_scores],axis=0)\n",
    "                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTS THE ABOVE CODE FOR CORRECTNESS\n",
    "interesting = qjoin_afs.loc[lambda df:(df.mutant_start_position == 285377) & (df.exp_type==\"U2OS_WT\") & (df.affine_score_threshold==3)].sort_values(\"score\",ascending=False)\n",
    "foc_position = 285377\n",
    "oligos_overlap = obe.loc[obe.starts.isin(range(foc_position - 150,foc_position)) & (obe.exp_type==\"U2OS_WT\")]\n",
    "mut_seq = chrseq[region_bounds[0]:region_bounds[1]][foc_position:foc_position+30]\n",
    "sequences = pd.concat([oligos_overlap.oligo,oligos_overlap.Sequences.str.contains(mut_seq).rename(\"contains_mut\"), oligos_overlap.Sequences.str.contains(\"GGGGAATTCC\").rename(\"contains_motif\")],axis=1)\n",
    "np.log2(sequences.merge(interesting.loc[lambda x: x[\"quantile\"]==.98].loc[lambda df: df.jaspar_id ==31], on =\"oligo\")[[\"contains_mut\",\"mu\",\"contains_motif\",\"oligo\",\"jaspar_id\",\"is_ablation_mut\"]].fillna(0).groupby(\"is_ablation_mut\").mu.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_hits_of_interest = motif_oligos_data.loc[lambda x: x.affine_score > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_filter_color_counts = pd.DataFrame()\n",
    "len(motif_hits_of_interest)\n",
    "for q in quantiles[\"quantile\"].unique():\n",
    "    qsel = qjoin_afs.loc[lambda x: x[\"quantile\"] == q] \n",
    "    motif_filter_color_counts = motif_filter_color_counts.append(\n",
    "        pd.concat([\n",
    "            qsel.groupby(['jaspar_id','exp_type',\"affine_score_threshold\"]).filter_color.value_counts().rename(\"fc_count\"),\n",
    "            \n",
    "        ],axis = 1).join(motif_hits_of_interest.groupby(['jaspar_id']).size().rename(\"n_total_hits\")).assign(quantile=q)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = pd.IndexSlice\n",
    "# motif_filter_color_counts.loc[idx[:, :,3,3], idx[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_fcc_selected =  \\\n",
    "    motif_filter_color_counts.reset_index().loc[lambda x: (x[\"quantile\"] ==.9) & (x[\"affine_score_threshold\"] ==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaspar_overall_frac_interesting = (motif_fcc_selected.loc[lambda x:x.filter_color>0].groupby(\"jaspar_id\").fc_count.sum()/\\\n",
    "    motif_fcc_selected.groupby(\"jaspar_id\").fc_count.sum()).fillna(0).rename(\"fraction_interesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jaspar_overall_rank = jaspar_overall_frac_interesting.reset_index().sort_values(\"fraction_interesting\",ascending=False)\\\n",
    "    .reset_index().set_index(\"jaspar_id\")[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_filter_color_counts = motif_filter_color_counts.join(jaspar_overall_rank,on=\"jaspar_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_motif_enriched3 = motif_filter_color_counts.reset_index(\"filter_color\").groupby([\"jaspar_id\",\"exp_type\",\"affine_score_threshold\",\"quantile\"])\\\n",
    "    .apply(lambda x:  x.set_index(\"filter_color\").loc[3].fc_count.sum()/x.set_index(\"filter_color\").loc[:].fc_count.sum() if (3 in x.filter_color.values )  else 0 ).rename(\"color_3_enrichment\")\n",
    "frac_motif_enriched2 = motif_filter_color_counts.reset_index(\"filter_color\").groupby([\"jaspar_id\",\"exp_type\",\"affine_score_threshold\",\"quantile\"])\\\n",
    "    .apply(lambda x:  x.set_index(\"filter_color\").loc[2].fc_count.sum()/x.set_index(\"filter_color\").loc[:].fc_count.sum() if (2 in x.filter_color.values )   else 0 ).rename(\"color_2_enrichment\")\n",
    "frac_motif_enriched1 = motif_filter_color_counts.reset_index(\"filter_color\").groupby([\"jaspar_id\",\"exp_type\",\"affine_score_threshold\",\"quantile\"])\\\n",
    "    .apply(lambda x:  x.set_index(\"filter_color\").loc[1].fc_count.sum()/x.set_index(\"filter_color\").loc[:].fc_count.sum() if (1 in x.filter_color.values )  else 0 ).rename(\"color_1_enrichment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "motif_filter_color_counts = motif_filter_color_counts.set_index(\"quantile\",append=True).join(frac_motif_enriched1)\\\n",
    "    .join(frac_motif_enriched2)\\\n",
    "    .join(frac_motif_enriched3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(x=\"index\", y = \"color_2_enrichment\", hue =\"quantile\", data = motif_filter_color_counts.reset_index())\n",
    "\n",
    "color_enrichments = motif_filter_color_counts.reset_index().melt(\n",
    "    id_vars=[\"jaspar_id\",\"index\",\"quantile\"],\n",
    "    value_vars = [\"color_1_enrichment\",\"color_2_enrichment\",\"color_3_enrichment\"],\n",
    "    value_name = \"enrichment_value\",\n",
    "    var_name =\"enrichment_type\",\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "sns.lineplot(x = \"index\", y = \"enrichment_value\", hue = \"enrichment_type\", data = color_enrichments.loc[lambda x:x[\"quantile\"]==.85])\n",
    "             \n",
    "\n",
    "plt.figure()\n",
    "sns.lineplot(x=\"index\", y = \"color_3_enrichment\", hue =\"exp_type\",\n",
    "             data = motif_filter_color_counts.reset_index().loc[lambda x:x[\"quantile\"] ==.75])\n",
    "\n",
    "plt.figure()\n",
    "sns.lineplot(x=\"index\", y = \"color_3_enrichment\", hue =\"exp_type\",\n",
    "             data = motif_filter_color_counts.reset_index().loc[lambda x:x[\"quantile\"] ==.85])\n",
    "\n",
    "plt.figure()\n",
    "sns.lineplot(x=\"index\", y = \"color_1_enrichment\", hue =\"exp_type\",\n",
    "             data = motif_filter_color_counts.reset_index().loc[lambda x:x[\"quantile\"] ==.95])\n",
    "\n",
    "plt.figure()\n",
    "sns.lineplot(x=\"index\", y = \"color_1_enrichment\", hue =\"exp_type\",\n",
    "             data = motif_filter_color_counts.reset_index().loc[lambda x:x[\"quantile\"] ==.85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(motif_filter_color_counts.reset_index()\\\n",
    "    .loc[lambda x:(x[\"quantile\"] ==.9) & (x[\"affine_score_threshold\"] == 2) ]\n",
    "    .groupby([\"jaspar_id\",\"exp_type\"]).color_3_enrichment.max().unstack()>.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_filter_color_counts.reset_index(\"affine_score_threshold\").affine_score_threshold.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_filter_color_counts.loc[(idx[:],idx[:],idx[3]),:].color_3_enrichment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 2\n",
    "\n",
    "\n",
    "    \n",
    "plt.imshow(motif_filter_color_counts.reset_index()\\\n",
    "    .loc[lambda x:(x[\"quantile\"] ==.9) & (x[\"affine_score_threshold\"] == thr) ]\n",
    "    .groupby([\"jaspar_id\",\"exp_type\"]).color_3_enrichment.max().unstack()>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 2\n",
    "color3 = motif_filter_color_counts.reset_index()\\\n",
    "    .loc[lambda x:(x[\"quantile\"] ==.9) & (x[\"affine_score_threshold\"] == thr) &  (x[\"color_3_enrichment\"] >0 ) ]\n",
    "\n",
    "U2_oligos =pd.concat( [\n",
    "                       pd.Series(\"activator\",index = EXP_activator_oligos.loc[\"U2OS_WT\"].oligo),\n",
    "pd.Series(\"repressor\",index = EXP_repressor_oligos.loc[\"U2OS_WT\"].oligo),\n",
    "    pd.Series(\"null\",index = EXP_null_oligos.loc[\"U2OS_WT\"].oligo)\n",
    "],axis = 0).rename(\"otype\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oligo_types = U2_oligos.to_frame().set_index(\"otype\",append=True).assign(val=1).reset_index().pivot_table(index=\"oligo\",columns=\"otype\")[\"val\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modata_thr = motif_oligos_data.loc[lambda x:(x.affine_score > thr) & (x.is_overlapping_wt)].set_index(\"jaspar_id\").sort_index()\n",
    "motif_wt_oligo_counts = jaspar.reset_index().apply(lambda x: len(modata_thr.loc[x.jaspar_id]) if x.jaspar_id in modata_thr.index.get_level_values(0) else 0,axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oligo_type_counts =  modata_thr.groupby(\"jaspar_id\").apply(lambda g1:\n",
    "oligo_types.apply( \n",
    "    lambda y:\n",
    "y.loc[[e for e in g1.oligo.unique() if e in y.index]].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oligo_type_fracs = oligo_type_counts.apply(lambda x: x / x.sum(), axis =1).fillna(0) / oligo_type_fracs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(motif_filter_color_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_counts_2d = (motif_filter_color_counts.reset_index()\\\n",
    "    .loc[lambda x:(x[\"quantile\"] ==.95) & (x[\"affine_score_threshold\"] == 1) ]\\\n",
    "    .groupby([\"jaspar_id\",\"exp_type\"]).color_1_enrichment.max().unstack() ) * 1 \n",
    "color_counts_2d = color_counts_2d /color_counts_2d.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(pd.concat([color_counts_2d, oligo_type_fracs[[\"activator\",\"null\",\"repressor\"]]],axis = 1).fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(motif_filter_color_counts.reset_index()\\\n",
    "    .loc[lambda x:(x[\"quantile\"] ==.95) & (x[\"affine_score_threshold\"] == 1) ]\n",
    "    .groupby([\"jaspar_id\",\"exp_type\"]).color_1_enrichment.max().unstack().T>.0)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(oligo_type_fracs[[\"activator\",\"repressor\"]].T>.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOTIF ANALYSIS #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHICH MOTIFS ARE FOUND IN REGIONS OF DIFFERENTIAL EXPRESSION BETWEEN WILD-TYPE CELLS? ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs are found in regions of differential expression between WT & perturbed cell types? ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do enhancer regions exhibit differential activity in chemical perturbations of the cell types under study? \n",
    "\n",
    "We examined the same discrepancy measure in the context of cellular perturbations of U2OS and HCT116 cells. \n",
    "\n",
    "First, considering U2OS cells with NFKB1 and NFKB2 knockouts, we created the differential expression sets in the same manner as defined above and found [XXX] enhancer regions to exhibit differential expression activation “NFKB-enhancers”, including [XXX] enhancers with ranksort values which changed by more than 3 STANDARD DEVIATIONS. Sorting these cells to look at only GFP negative cells, we found [XXX] enhancers with ranksort values which changed by 3 STANDARD DEVIATIONS.\n",
    "\n",
    "Next, considering HCT116 cells subjected to treatment with 2uM gemtabicine, we found [XXX] enhancer regions exhibiting differential expression “GEMTAB-enhancers”. Amongst these, [XXX] of the enhancer regions had a ranksort difference of 3 STANDARD DEVIATIONS. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCT116_perturbation_on =pd.Series(True, index =  diffex.loc[lambda x: (x.expressed==\"HCT116_WT\") & (x.unexpressed==\"HCT116_GEM\")].oligo).rename(\"HCT116_perturbed_off\")\n",
    "HCT116_perturbation_off =  pd.Series(True, index = diffex.loc[lambda x: (x.expressed==\"HCT116_GEM\") & (x.unexpressed==\"HCT116_WT\")].oligo).rename(\"HCT116_perturbed_on\")\n",
    "U2OS_knockout_on = pd.Series(True, index =   diffex.loc[lambda x: (x.expressed==\"U2OS_WT\") & (x.unexpressed==\"U2OS_NFKB\")].oligo).rename(\"U2OS_perturbed_off\")\n",
    "U2OS_knockout_off =  pd.Series(True, index= diffex.loc[lambda x: (x.expressed==\"U2OS_NFKB\") & (x.unexpressed==\"U2OS_WT\")].oligo).rename(\"USOS_perturbed_on\")\n",
    "perturbations = pd.concat([HCT116_perturbation_off,HCT116_perturbation_on,U2OS_knockout_off,U2OS_knockout_on],axis=1)\n",
    "affine_score_threshold = 1\n",
    "jaspar_perturbation_hits = perturbations.apply(lambda x: motif_oligos_data.loc[lambda x: x.affine_score >affine_score_threshold].groupby(\"jaspar_id\").apply(lambda g:len(g.join(x.dropna(),on = \"oligo\",how =\"inner\").oligo.unique()))).reset_index()\n",
    "jaspar_perturbation_fracs = perturbations.apply(lambda p: motif_oligos_data.loc[lambda df: df.affine_score >affine_score_threshold].groupby(\"jaspar_id\").apply(lambda g:len(g.join(p.dropna(),on = \"oligo\",how =\"inner\").oligo.unique())/(g.oligo.nunique()*len(p.dropna())))).reset_index()\n",
    "jaspar_perturbation_fracs_unstacked = jaspar_perturbation_fracs.melt(id_vars = \"jaspar_id\", value_name =\"hit_frac\",var_name=\"perturbation_type\")\n",
    "sns.scatterplot(x=\"jaspar_id\",y=\"hit_frac\", hue=\"perturbation_type\", data = jaspar_perturbation_fracs_unstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOTIF DISCOVERY #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs do we discover in the unfiltered intervals ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "root = ET.parse('/Users/ben/src/meme-5.0.5/meme_out_2200/meme.xml').getroot()\n",
    "#arrays = [[[{e.attrib[\"letter_id\"]: e.text} for e in v if e.attrib[\"letter_id\"] in \"ATGC\"] for v in c[1].getchildren()[0].getchildren()] for c in root.getchildren()[2].getchildren()]\n",
    "arrays = [[dict([[e.attrib[\"letter_id\"],np.round( float(e.text) * 100)] for e in v if e.attrib[\"letter_id\"] in \"ATGC\"]) for v in c[1].getchildren()[0].getchildren()] for c in root.getchildren()[2].getchildren()]\n",
    "\n",
    "from Bio.motifs import jaspar\n",
    "import io\n",
    "import Bio\n",
    "from Bio.Alphabet import IUPAC\n",
    "motifs_string = \"\\n\".join([\">TEST{0} {0}\\n\".format(i) + \"\\n\".join([k + \" [\"+\" \".join([str(int(d[k])) for d in positions] ) +\"]\" for k in \"ATGC\"]) \n",
    "     for i, positions in enumerate(arrays)])\n",
    "f = io.StringIO(motifs_string)\n",
    "meme_motifs = jaspar.read(f,\"jaspar\")\n",
    "intervals[\"bioseq\"] = intervals.seq.apply(lambda x: Bio.Seq.Seq(x,alphabet = Bio.Alphabet.IUPAC.IUPACUnambiguousDNA()))\n",
    "\n",
    "for mm in meme_motifs: mm.pseudocounts = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs do we discover in the expressed oligos? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[TODO] run meme on the expressed oligos only, using the negative null set as the background control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do the set of discovered motifs compare to the reference set? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaspar = z2_save_jaspar.load_jaspar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes =pd.Series(meme_motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes = meme_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaspar_array = np.array(list(e for e in jaspar.pwm.apply(lambda x: [e for k in \"ATGC\" for e in list(x[k])+([0]*(25 - len(x[k])))]).values))\n",
    "memes_array = np.array(list(e for e in memes.apply(lambda x: [e for k in \"ATGC\" for e in list(x.pwm[k])+([0]*(25 - len(x.pwm[k])))]).values))\n",
    "sns.clustermap(np.matmul( (jaspar_array / jaspar_array.sum(axis=1)[:,np.newaxis]),(memes_array/memes_array.sum(axis=1)[:,np.newaxis]).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADS BIOLOGICAL MOTIFS AND SCANS ALL SUBREGIONS FOR OCCURENCES\n",
    "from pyfaidx import Fasta\n",
    "sequences_fa = Fasta('/Users/ben/genomes/GRCh38.primary_assembly.genome.fa')\n",
    "chrseq = str(sequences_fa[\"chr22\"])\n",
    "region_bounds=[ 38699734, 39291007]\n",
    "background = dict([[l,chrseq[region_bounds[0]:region_bounds[1]].count(l) / len(chrseq[region_bounds[0]:region_bounds[1]])] for l in \"ATGC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_hits = memes.apply(lambda mm: intervals.apply(lambda x:[ e for e in  mm.pssm.search(x.bioseq)] , axis = 1))\n",
    "meme_unstacked =pd.concat(\n",
    "    [meme_hits.stack().groupby(level=[0,1]).apply(lambda g: pd.Series([e[0] for r in g for e in r])).rename(\"instance_idx\"),\n",
    "     meme_hits.stack().groupby(level=[0,1]).apply(lambda g: pd.Series([e[1] for r in g for e in r])).rename(\"instance_score\")]\n",
    "    ,axis = 1)\n",
    "\n",
    "meme_unstacked.index.levels[0].name=\"meme_motif\"\n",
    "meme_unstacked.index.levels[1].name=\"interval_id\"\n",
    "meme_unstacked = meme_unstacked.reset_index(level=[\"meme_motif\",\"interval_id\"]).reset_index(drop = True)\n",
    "meme_unstacked = meme_unstacked.join(memes.apply(lambda x:str(x.consensus)).rename(\"consensus\"),on = \"meme_motif\")\n",
    "meme_unstacked = meme_unstacked.join(intervals[[\"start\",\"end\",\"seq\"]], on = \"interval_id\")\n",
    "meme_unstacked[\"instance_position\"] = meme_unstacked.apply(\n",
    "    lambda x:x.start + x.instance_idx if x.instance_idx >= 0 else x.end + x.instance_idx,axis =1)\n",
    "meme_unstacked[\"instance_seq\"] = meme_unstacked.apply(lambda x:x.seq[x.instance_position - x.start:][:len(x.consensus)], axis = 1)\n",
    "\n",
    "#LOADS BIOLOGICAL MOTIFS AND SCANS ALL SUBREGIONS FOR OCCURENCES\n",
    "from pyfaidx import Fasta\n",
    "sequences_fa = Fasta('/Users/ben/genomes/GRCh38.primary_assembly.genome.fa')\n",
    "chrseq = str(sequences_fa[\"chr22\"])\n",
    "region_bounds=[ 38699734, 39291007]\n",
    "background = dict([[l,chrseq[region_bounds[0]:region_bounds[1]].count(l) / len(chrseq[region_bounds[0]:region_bounds[1]])] for l in \"ATGC\"])\n",
    "\n",
    "memes_patser = memes.apply(lambda x: x.pssm.distribution(background=background, precision=10**3).threshold_patser())\n",
    "meme_unstacked = meme_unstacked.join(memes_patser.rename(\"motif_threshold_patser\"),on=\"meme_motif\")\n",
    "meme_unstacked[\"affine_score\"] = meme_unstacked[\"instance_score\"] - meme_unstacked[\"motif_threshold_patser\"]\n",
    "meme_unstacked[\"instance_identity\"] = meme_unstacked[[\"instance_seq\",\"consensus\"]].apply(lambda x: float(len([ i for i,l in enumerate(x.instance_seq) if l == x.consensus[i]]))/len(x.consensus),axis=1)\n",
    "\n",
    "\n",
    "sns.scatterplot( x = \"instance_identity\", y = \"affine_score\", data= meme_unstacked)\n",
    "plt.figure()\n",
    "sns.scatterplot( x = \"meme_motif\", y = \"affine_score\", data= meme_unstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX #\n",
    "Additional figureds which may be useful in understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPENDIX A: RANKSORT DISCREPANCIES ###\n",
    "The selection of APOBEC-differential-activators was performed based on a change in the ranksorted expression levels between the two APOBEC expressing cell types under study. For this to be a valid measure, we would hope that the majority of activators were discovered in both cell types and that their differences fell under the differential expression threshold. \n",
    "\n",
    "This is the case to a limited extent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f,subs = plt.subplots(2,2)\n",
    "f.set_size_inches(7,7)\n",
    "plt.sca(subs[0][0])\n",
    "sns.scatterplot(obe.U2OS_WT_rank,obe.DLD1_WT_rank)\n",
    "\n",
    "plt.sca(subs[0][1])\n",
    "\n",
    "sns.scatterplot(\n",
    "    x = \"U2OS_WT_rank\",\n",
    "    y = \"DLD1_WT_rank\",\n",
    "    data =  obe.loc[lambda x: x.oligo.isin(ABon_ids)],\n",
    ")\n",
    "plt.gca().set_title(f\"rank of {len(ABon_ids)} ABex oligo ranks\")\n",
    "\n",
    "\n",
    "plt.sca(subs[1][0])\n",
    "sns.scatterplot(\n",
    "    x = \"U2OS_WT_rank\",\n",
    "    y = \"DLD1_WT_rank\",\n",
    "    data =  obe.loc[lambda x: x.oligo.isin(U2on_ids)],\n",
    ")\n",
    "plt.gca().set_title(f\"rank of {len(U2on_ids)} U2on oligo ranks\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gca().set_xlim([0,200])\n",
    "plt.gca().set_ylim([0,200])\n",
    "\n",
    "\n",
    "plt.sca(subs[1][1])\n",
    "sns.scatterplot(\n",
    "    x = \"U2OS_WT_rank\",\n",
    "    y = \"U2OS_NFKB_rank\",\n",
    "    data =  obe.loc[lambda x: x.oligo.isin(U2on_ids)],\n",
    ")\n",
    "plt.gca().set_title(f\"rank of {len(U2on_ids)} ABon oligo ranks\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gca().set_xlim([0,200])\n",
    "plt.gca().set_ylim([0,200])\n",
    "\n",
    "f = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_title (\"histogram of rank change differenes between DLD1 and U2OS\\n expression levels for all oligos in APOBEC-sometimes\")\n",
    "\n",
    "plt.hist(  (obe.loc[lambda x:x.oligo.isin(ABst_ids)].DLD1_WT_rank - \n",
    "            obe.loc[lambda x:x.oligo.isin(ABst_ids)].U2OS_WT_rank ).abs() ,\n",
    "        bins = np.arange(0,1000,50))\n",
    "\n",
    "f = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_title (\"histogram of rank change differenes between DLD1 and U2OS\\n expression levels for all oligos\")\n",
    "\n",
    "plt.hist(  (obe.DLD1_WT_rank - obe.U2OS_WT_rank ).abs(),\n",
    "         bins = np.arange(0,1000,50) )\n",
    "\n",
    "\n",
    "# obe_win = obe.loc[lambda x: x.oligo.isin(U2on_ids)]\n",
    "# from scipy import stats\n",
    "# def r2(x, y):\n",
    "#     return stats.pearsonr(x, y)[0] ** 2\n",
    "\n",
    "# def pval(x, y):\n",
    "#     return stats.pearsonr(x, y)[1] ** 2\n",
    "\n",
    "# sns.jointplot(\"U2OS_WT_rank\",\"DLD1_WT_rank\", kind=\"reg\", stat_func=r2,data = obe_win)\n",
    "# #sns.regplot(\"U2OS_WT_rank\",\"DLD1_WT_rank\",data = obe_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_activator_oligos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
