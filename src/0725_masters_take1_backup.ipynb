{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pprint import pprint\n",
    "import z2_save_jaspar, z1_save_oligos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD JASPAR & OLIGO DATA\n",
    "jaspar = z2_save_jaspar.load_jaspar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADS BIOLOGICAL MOTIFS AND SCANS ALL SUBREGIONS FOR OCCURENCES\n",
    "from pyfaidx import Fasta\n",
    "sequences_fa = Fasta('/Users/ben/genomes/GRCh38.primary_assembly.genome.fa')\n",
    "chrseq = str(sequences_fa[\"chr22\"])\n",
    "region_bounds=[ 38699734, 39291007]\n",
    "background = dict([[l,chrseq[region_bounds[0]:region_bounds[1]].count(l) / len(chrseq[region_bounds[0]:region_bounds[1]])] for l in \"ATGC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oligos, oligos_by_exp_some,oligos_by_exp = z1_save_oligos.load_oligos()\n",
    "oligos_by_exp = oligos_by_exp.filter(regex='^(?!exp|\\\\.).*')\n",
    "oligos_by_exp[\"exp_nm\"] = oligos_by_exp.index.get_level_values(\"exp\").to_series().apply(lambda x:re.compile('(.*)_BR').search(x).groups()[0]).values\n",
    "oligos_by_exp = oligos_by_exp.reset_index()\n",
    "\n",
    "oligos_by_exp[\"exp_ct\"] = oligos_by_exp.exp_nm.apply(lambda x:re.compile(\"(U2OS|DLD1|HCT116)\").search(x).groups()[0])\n",
    "oligos_by_exp[\"exp_type\"] = oligos_by_exp.exp_nm.apply(lambda x:\"U2OS_NFKB\" if \"NFKB\" in x \n",
    "                                                     else (\"HCT116_GEM\") if \"Gem\" in x\n",
    "                                                     else re.compile(\"(U2OS|DLD1|HCT116)\").search(x).groups()[0]+\"_WT\")\n",
    "\n",
    "oligos[\"mutant_start\"] = oligos.mutant_start + 30\n",
    "oligos_by_exp[\"mutant_start\"] = oligos_by_exp.mutant_start + 30\n",
    "oligos_by_exp[\"mutant_start\"] = oligos_by_exp.apply(lambda x:np.nan if x.mutant_num == 0 else x.mutant_start,axis=1)\n",
    "oligos[\"mutant_start\"] = oligos.apply(lambda x:np.nan if x.mutant_num == 0 else x.mutant_start,axis=1)\n",
    "\n",
    "ranks = oligos_by_exp.loc[lambda x:x.mutant_num == 0].groupby(\"exp_type\").\\\n",
    "    apply(lambda x:x.groupby(\"oligo\").mu.mean().sort_values(ascending=False).\\\n",
    "          reset_index().reset_index().set_index(\"oligo\").\\\n",
    "        rename({\"index\":\"ranksort\"},axis=\"columns\").\\\n",
    "        ranksort).unstack(level=0).rename(lambda x: x+\"_rank\",axis = \"columns\")\n",
    "oligos_by_exp = oligos_by_exp.join(ranks, on=\"oligo\")\n",
    "\n",
    "obe = oligos_by_exp\n",
    "\n",
    "#LOADS MOTIF DATA\n",
    "motif_oligos_data = pd.read_csv(\"../out/0722_motif_oligos_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_oligos_data =  motif_oligos_data.join(jaspar.filter(regex=\"threshold_.*\"),on=\"jaspar_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "motif_oligos_data[\"affine_score\"] = motif_oligos_data.score - motif_oligos_data[[\"threshold_patser\",\"threshold_fdr_005\"]].T.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ranks_by_rep = oligos_by_exp.loc[lambda x:x.mutant_num == 0].groupby([\"exp_type\",\"rep\"]).\\\n",
    "    apply(lambda x:x.groupby(\"oligo\").mu.mean().sort_values(ascending=False).\\\n",
    "          reset_index().reset_index().set_index(\"oligo\").\\\n",
    "        rename({\"index\":\"ranksort\"},axis=\"columns\").\\\n",
    "        ranksort).unstack(level=0).rename(lambda x: x+\"_rank\",axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obe_w_repchanges = oligos_by_exp.join(\n",
    "    (ranks_by_rep.loc[1] - ranks_by_rep.loc[2]).rename(lambda x:x+\"_repchange\",axis =\"columns\")\n",
    "    ,on=\"oligo\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = pd.read_csv(\"../out/0729_intervals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_score_threshold = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDENTIFICATION AND DESCRIPTION OF HIGHLY EXPRESSED ENHANCER CANDIDATES IN MULTIPLE CELL TYPES ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Where are the promoters/enhancers (STARR-Seq peaks) as defined by this assay for this data in an overall pool? ####  \n",
    "In the aggregate pooled data, on average [n_tx_mean] transcripts are identified for [n_bcs_total] barcodes (n_bcs_per_oligos. The number of transcripts can be counted per barcode, giving a number for the expression rate of the that barcode which is comparable between [SEE APPENDIX A, TRANSCRIPT COUNTING] barcoded plasmids in all of our pooled sequencing. We call this transcription rate “μ” the pooled expression of a given oligo, which can be defined on a per-experiment or pooled basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint({\n",
    "    \"n_tx_mean\":oligos.n_transcripts.mean(),\n",
    "    \"n_bcs_total\":oligos.n_bcs.sum(),\n",
    "    \"n_bcs_avg\":oligos.n_bcs.mean(),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering μ over all oligo start positions, we observe ~4-5 variants of each oligo and average this quantity together to define an average expression level. Considering all such oligo-averaged expression levels, we can define peaks of expression, or putative enhancer sequences. Going forward, we define the top 5% of oligo positions by location as potential enhancer sequences “POOL-activators”. A total of [POOL_activator_len] positions of 2000 are captured by this method and defined as pooled enhancers. Likewise, the bottom 5% “POOL-repressors” of oligos by expression are split into a separate group and identified as repressors, whereas the bottom 50%of oligos are identified and described as the null background “POOL-null”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_oligos = oligos.loc[lambda x: x.mutant_num ==0]\n",
    "POOL_activators = wt_oligos.loc[lambda x: x.mu > x.mu.quantile(.95)]\n",
    "POOL_repressors = wt_oligos.loc[lambda x: x.mu < x.mu.quantile(.05)]\n",
    "POOL_null = wt_oligos.loc[lambda x: x.mu < x.mu.quantile(.5)]\n",
    "\n",
    "print({\n",
    "    \"POOL_activator_len\": len(POOL_activators),\n",
    "    \"POOL_repressor_len\": len(POOL_repressors),\n",
    "    \"POOL_null_len\": len(POOL_null),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second performing the same analysis as above, we identified a set of 5% expressed oligos, repressed oligos, and null / negative control oligos for each replicate of each experiment “{EXP_N}-activators” / “{EXP_N}-repressors”. For each experiment, we then take an intersection of the activators, repressors, and null negative control oligos observed in the two replicates of each experiment, finding that on average 67% of these oligos are observed in both replicates over all experiments. Looking at each experiment individually, the U2OS and DLD1 cell types have replicable discovery rates of 79% and 67% respectively, with U2OS cell-type having the highest replicability overall We find that activators are overall more replicable than repressors, which is as expected based upon the distribution of log scores for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_REP_activators = oligos_by_exp.loc[lambda x:x.mutant_num==0].groupby(\"exp\").apply(lambda x: x.loc[x.mu > x.mu.quantile(.95)])\n",
    "EXP_REP_repressors = oligos_by_exp.loc[lambda x:x.mutant_num==0].groupby(\"exp\").apply(lambda x: x.loc[x.mu < x.mu.quantile(.05)])\n",
    "EXP_REP_null = oligos_by_exp.loc[lambda x:x.mutant_num==0].groupby(\"exp\").apply(lambda x: x.loc[x.mu < x.mu.quantile(.5)])\n",
    "\n",
    "EXP_activator_oligos = EXP_REP_activators.groupby(\"exp_nm\").apply(lambda g1:g1.loc[g1.oligo.isin(g1.set_index(\"rep\").loc[1].oligo) & g1.oligo.isin(g1.set_index(\"rep\").loc[2].oligo)])\n",
    "EXP_repressor_oligos = EXP_REP_repressors.groupby(\"exp_nm\").apply(lambda g1:g1.loc[g1.oligo.isin(g1.set_index(\"rep\").loc[1].oligo) & g1.oligo.isin(g1.set_index(\"rep\").loc[2].oligo)])\n",
    "EXP_null_oligos = EXP_REP_null.groupby(\"exp_nm\").apply(lambda g1:g1.loc[g1.oligo.isin(g1.set_index(\"rep\").loc[1].oligo) & g1.oligo.isin(g1.set_index(\"rep\").loc[2].oligo)])\n",
    "\n",
    "EXP_activator_rep_rate =  EXP_activator_oligos.groupby(level=\"exp_nm\").apply(lambda x:x.oligo.nunique()) / EXP_REP_activators.groupby(\"exp_nm\").apply(lambda x:x.groupby(\"rep\").oligo.nunique().mean())\n",
    "EXP_repressor_rep_rate =  EXP_repressor_oligos.groupby(level=\"exp_nm\").apply(lambda x:x.oligo.nunique()) / EXP_REP_repressors.groupby(\"exp_nm\").apply(lambda x:x.groupby(\"rep\").oligo.nunique().mean())\n",
    "EXP_null_rep_rate =  EXP_null_oligos.groupby(level=\"exp_nm\").apply(lambda x:x.oligo.nunique()) / EXP_REP_null.groupby(\"exp_nm\").apply(lambda x:x.groupby(\"rep\").oligo.nunique().mean())\n",
    "#EXP_repressor_rep_rate =  EXP_repressor_oligos.groupby(level=\"exp_nm\").reset_index(\"oligo\").oligo.nunique().mean() / EXP_REP_repressors.groupby(\"exp_nm\").reset_index(\"oligo\").oligo.nunique()\n",
    "\n",
    "DLD1_activator_rediscovery_rate = EXP_activator_rep_rate.loc[\"DLD1_WT\"]\n",
    "U2OS_activator_rediscovery_rate = EXP_activator_rep_rate.loc[\"U2OS_WT\"]\n",
    "MAX_activator_rediscovery_celltype = EXP_activator_rep_rate.idxmax()\n",
    "\n",
    "pprint({\n",
    "    \"EXP_activators_mean_len\":EXP_activator_oligos.groupby(level=\"exp_nm\").oligo.nunique().mean(),\n",
    "    \"EXP_repressors_mean_len\":EXP_repressor_oligos.groupby(level=\"exp_nm\").oligo.nunique().mean(),\n",
    "    \"EXP_null_mean_len\":EXP_null_oligos.groupby(level=\"exp_nm\").oligo.nunique().mean(),\n",
    "    \"EXP_repressor__mean_rep_rate\":EXP_repressor_rep_rate.mean(),\n",
    "    \"EXP_activator_mean_rep_rate\":EXP_activator_rep_rate.mean(),\n",
    "    \"EXP_null_mean_rep_rate\":EXP_null_rep_rate.mean(),\n",
    "    \"U2OS_activator_rediscovery_rate\":U2OS_activator_rediscovery_rate,\n",
    "    \"DLD1_activator_rediscovery_rate\":DLD1_activator_rediscovery_rate,\n",
    "    \"MAX_activator_rediscovery_celltype\":MAX_activator_rediscovery_celltype,\n",
    "    \"EXP_activator_rep_rate\": EXP_activator_rep_rate,\n",
    "})\n",
    "\n",
    "\n",
    "plt.gcf().set_size_inches(6,4)\n",
    "ax = plt.gca()\n",
    "plt.hist([(np.log2(g.mu) - np.log2(g.mu.mean())).rename(k) for k, g in oligos_by_exp.groupby(\"exp_nm\")])\n",
    "\n",
    "ax.set_title(\"histogram of normalized log2 expression rates by experiment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing that APOBEC is expressed in DLD1 and U2OS cells, we defined a further set of activators defined as “APOBEC-on” enhancers, consisting of those enhancers which were identified both in the DLD1 replicates and the U2OS replicates, this set had {100} elements. Lastly, observing that APOBEC is not expressed in HCT116 cells, we defined a final set of activators of interest, consisting of {59} possible transcription activators which exhibited high transcription in U2OS and DLD1 cells (ie, in the APOBEC-on enhancers), but not in HCT116 cells. These were called “APOBEC-exclusive” candidate enhancer regions. Observing that U2OS expression tended to differ greatly with DLD1 expression, and U2OS expression was overall higher, we also investigated another set, \"U2OS-on\", with U2OS-identified enhancers, excluding those which were detected in HCT116 peaks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "APOBEC_on_oligo_ids = set(EXP_activator_oligos.loc[\"DLD1_WT\"].oligo).intersection(EXP_activator_oligos.loc[\"U2OS_WT\"].oligo)\n",
    "APOBEC_sometimes_oligo_ids = set(EXP_activator_oligos.loc[\"DLD1_WT\"].oligo).union(EXP_activator_oligos.loc[\"U2OS_WT\"].oligo)\n",
    "ABon_ids = APOBEC_on_oligo_ids\n",
    "ABst_ids = APOBEC_sometimes_oligo_ids\n",
    "\n",
    "\n",
    "APOBEC_exclusive_oligo_ids =APOBEC_on_oligo_ids.difference(EXP_activator_oligos.loc[\"HCT116_WT\"].oligo)\n",
    "U2OS_on_oligo_ids = set(EXP_activator_oligos.loc[\"U2OS_WT\"].oligo)\n",
    "\n",
    "\n",
    "ABex_ids = APOBEC_exclusive_oligo_ids \n",
    "U2on_ids = U2OS_on_oligo_ids\n",
    "U2ex_ids = set(U2OS_on_oligo_ids).difference(EXP_activator_oligos.loc[\"HCT116_WT\"].oligo)\n",
    "\n",
    "ALLen_ids = set(EXP_activator_oligos.oligo)\n",
    "WTst_ids =APOBEC_sometimes_oligo_ids.union(EXP_activator_oligos.loc[\"HCT116_WT\"].oligo)\n",
    "\n",
    "\n",
    "AB_differential_enhancer_ids = obe.loc[lambda x: x.oligo.isin(ABst_ids)].\\\n",
    "        loc[lambda df:abs(df.U2OS_WT_rank -df.DLD1_WT_rank) > 100].oligo.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oligo_exp_activator_matrix = pd.Series(1, index =EXP_activator_oligos.oligo.to_frame().reset_index().set_index([\"exp_nm\",\"oligo\"]).index).loc[lambda df: ~df.index.duplicated(keep='first') ].unstack(\"exp_nm\").fillna(0)\n",
    "oligo_exp_activator_matrix = oligo_exp_activator_matrix.append( [ pd.Series(0, index = oligo_exp_activator_matrix.columns).rename(o) for o in [e for e in obe.oligo.unique() if e not in oligo_exp_activator_matrix.index] ])\n",
    "correlations = oligo_exp_activator_matrix.corr()\n",
    "for nm in correlations.columns: correlations.loc[nm,nm] = 0\n",
    "\n",
    "intersection_grid = np.array([[np.sum(oligo_exp_activator_matrix[c1].values * oligo_exp_activator_matrix[c2].values)\n",
    "     for c1 in oligo_exp_activator_matrix.columns ]\n",
    "     for c2 in oligo_exp_activator_matrix.columns])\n",
    "\n",
    "sns.clustermap((oligo_exp_activator_matrix.loc[oligo_exp_activator_matrix.sum(axis=1) >0].filter(regex=\".*WT.*\" )),figsize=(3,3))\n",
    "#sns.clustermap(oligo_exp_activator_matrix.filter(regex=\".*WT.*\" ).T.filter(regex=\".*WT.*\" ),figsize=(3,3))\n",
    "sns.clustermap((oligo_exp_activator_matrix.loc[oligo_exp_activator_matrix.sum(axis=1) >0]),figsize=(3,3))\n",
    "\n",
    "f,subs = plt.subplots(1,2)\n",
    "f.set_size_inches(9,5)\n",
    "\n",
    "plt.sca(subs[0])\n",
    "sns.lineplot(x = \"U2OS_WT_rank\", y = \"mu\",  hue = \"exp_nm\", data = oligos_by_exp.loc[lambda x: x.oligo.isin(EXP_activator_oligos.loc[\"U2OS_WT\"].oligo)])\n",
    "plt.legend(loc=[0,1.1])\n",
    "\n",
    "plt.sca(subs[1])\n",
    "sns.lineplot(x = \"DLD1_WT_rank\", y = \"mu\",  hue = \"exp_nm\", data = oligos_by_exp.loc[lambda x: x.oligo.isin(EXP_activator_oligos.loc[\"DLD1_WT\"].oligo)],legend=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do enhancer regions exhibit differential activity in the cell types under study? ####\n",
    "We had previously identified separate groups of top5% enhancers in each cell type under study. Furthermore, we observed that the groups of top5% enhancers were different for each of the cell types. To define APOBEC-on activators, we took an intersection of the top5% enhancers. To study differential expression in these cell types, we defined a new set of APOBEC-sometimes enhancer regions consisting of the union of top5% enhancer oligos in each of these (ABst) experiments. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There were {100} total enhancer locations in the ABst set. For each enhancer, we examined the descending rank-sorted order of that enhancer in the experimental data for that locus, assigning a number equal to the absolute value of that rank sort-order difference in each set to each of the APOBEC-somstetimes enhancer regions. Looking at the full set of APOBEC-sometimes enhancer regions, we found a mean ranksort discrepancy of {248} between the two data sets. To quantify significance of this number, we also computed the mean ranksort discrepancy of the APOBEC-sometimes enhancers in each of the two experimental replicates of DLD1 and U2OS. We found that the average absolute ranksort differential of APOBEC-sometimes enhancer candidates was [111] and [49] in the DLD1 and U2OS replicates respectively, with an overall mean of [250]. Importantly, we found that amongst the U2OSon and DLD1on oligos, the average rank changes between replicates was 7.63 and 12.75 respectively, leading us to conclude that for the most expressed oligos, the expression rank change provided an internally consistent number.\n",
    "\n",
    "Equipped with this measure, we set a threshold of rank expression change of 100 ranks and observed that 47 of the ABst potential enahncers changed in rank by 100 or more between the two experiments. We called these “APOBEC-differential-enhancers”, and noted that these 47 oligos were candidates for cell-type specific differential activation of APOBEC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abst_U2OSNKFB_U2OS_WT_rankdiff = obe.loc[lambda x: x.oligo.isin(ABst_ids)].\\\n",
    "        apply(lambda df:abs(df.U2OS_WT_rank -df.U2OS_NFKB_rank),axis=1)\n",
    "\n",
    "all_U2OSNKFB_U2OS_WT_rankdiff = obe.loc[lambda x:  x.mutant_num == 0].\\\n",
    "        apply(lambda df:abs(df.U2OS_WT_rank -df.U2OS_NFKB_rank),axis=1)\n",
    "\n",
    "abst_dld1_U2OS_WT_rankdiff = obe.loc[lambda x: x.oligo.isin(ABst_ids)].\\\n",
    "        apply(lambda df:abs(df.U2OS_WT_rank -df.DLD1_WT_rank),axis=1)\n",
    "\n",
    "all_dld1_U2OS_WT_rankdiff = obe.loc[lambda x: x.mutant_num == 0].\\\n",
    "        apply(lambda df:abs(df.U2OS_WT_rank -df.DLD1_WT_rank),axis=1)\n",
    "\n",
    "AB_differential_enhancer_ids = obe.loc[lambda x: x.oligo.isin(ABst_ids)].\\\n",
    "        loc[lambda df:abs(df.U2OS_WT_rank -df.DLD1_WT_rank) > 100].oligo.unique()\n",
    "\n",
    "print(f\"\"\" mean difference between rank sorts in U2OS vs DLD1 cells over--\n",
    "   ABST oligos: ({abst_dld1_U2OS_WT_rankdiff.mean():.2f})  \n",
    "   ALL wt oligos: ({all_dld1_U2OS_WT_rankdiff.mean():.2f})\n",
    "\n",
    "Looking at only U2OS cell lines in NFKB-ko and NFKB designs, we find that the differences are reduced\n",
    "   ABST oligos: ({abst_U2OSNKFB_U2OS_WT_rankdiff.mean():.2f})  \n",
    "   ALL oligos: ({all_U2OSNKFB_U2OS_WT_rankdiff.mean():.2f})  \n",
    "\n",
    "\n",
    "... and furthermore, that the rank change difference of expression levels amongst ABst expressed oligos is\n",
    "reduced compared to the rank change difference between all oligos. In order to quantify the base level of\n",
    "noise in rank fold change amongst all oligos, we looked at the average fold change difference between replicates,\n",
    "finding that the overall change in expression ranks for \n",
    "\n",
    "ALL OLIGOS (U2OS) {obe_w_repchanges[\"U2OS_WT_rank_repchange\"].abs().mean():.2f}\n",
    "ABST OLIGOS (U2OS) {obe_w_repchanges.loc[lambda x: x.oligo.isin(ABst_ids)][\"U2OS_WT_rank_repchange\"].abs().mean():.2f}\n",
    "ABST OLIGOS (U2OS) {obe_w_repchanges.loc[lambda x: x.oligo.isin(U2on_ids)][\"U2OS_WT_rank_repchange\"].abs().mean():.2f}\n",
    "\n",
    "\n",
    "ALL OLIGOS (DLD1) {obe_w_repchanges[\"DLD1_WT_rank_repchange\"].abs().mean():.2f}\n",
    "ABST OLIGOS (DLD1) {obe_w_repchanges.loc[lambda x: x.oligo.isin(ABst_ids)][\"DLD1_WT_rank_repchange\"].abs().mean():.2f}\n",
    "ABST OLIGOS (DLD1) {obe_w_repchanges.loc[lambda x: x.oligo.isin(EXP_activator_oligos.loc[\"DLD1_WT\"].oligo)][\"DLD1_WT_rank_repchange\"].abs().mean():.2f}\n",
    "\n",
    "Number of \"APOBEC-differentialy-expressed\" oligos:\n",
    "    {len(AB_differential_enhancer_ids)} \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from this measure of differential expression in wild-type cells that were highly expressive of APOBEC, we sought to apply the same measure to quantification of differential expression between the APOBEC-expressing cell lines and the HCT116 cell type which does not natively express APOBEC. Defining an inclusive set of enhancers, WILDTYPE-activators with [XXX] members, consisting of the top5% enhancers from DLD1, HCT116, and U2OS, we looked at differential expression, computed between all 3x3 cell types for each of these enhancers. We were also curious to see how differential expression of the bot5% would vary between these three cell types and therefore defined the set WILDTYPE-repressors and computed the same score, using all 3x3 comparisons.\n",
    "\n",
    "Using the same definitions above, we computed average and std deviation of ranksort discrepancies for activators ( [XXX]mean, [XXX]stddev ) and repressors  ( [XXX]mean, [XXX]stddev )  individually and identified as differentially expressed all those oligos which crossed the threshold of mean + 1 std discrepancy change. By this measure, we found that [XXX] / ([XXX]) oligos were differentially expressed between either DLD1 / (U2OS) and HCT116 cells respectively. We called their intersection, the “APOBEC-on-enhancers” (XXX regions). Comparing the set of oligos previously identified as in the DLD1 and U2OS sets but not in HCT116 cells (“ABOPEC-exclusive” oligos), we found that [XXX]% of APOBEC-exclusive oligos were found in this set of differentially expressed oligos, confirming the internal consistency of these two measures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obe_wtst = obe.loc[lambda x: x.oligo.isin(WTst_ids) ]\n",
    "celltypes = pd.Series([\"DLD1_WT\",\"U2OS_WT\",\"HCT116_WT\"], index = [\"DLD1_WT\",\"U2OS_WT\",\"HCT116_WT\"])\n",
    "exptypes = pd.Series(obe.exp_type.unique(), index = obe.exp_type.unique())\n",
    "\n",
    "enhancer_intersection_sizes = celltypes.apply(lambda x: celltypes.apply(lambda y:len(\n",
    "    set(EXP_activator_oligos.loc[x].oligo.unique()).intersection(\n",
    "    set(EXP_activator_oligos.loc[y].oligo.unique())))))\n",
    "\n",
    "WTst_differential_expression_count = \\\n",
    "exptypes.apply(lambda ct1: \n",
    "        exptypes.apply(lambda ct2:\n",
    "            len(set(obe_wtst.loc[lambda x:(abs(x[ct1 + \"_rank\"]  - x[ct2+\"_rank\"])) > 100].oligo.unique()))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "number of oligos highly expressed in at least one of: DLD1, U2OS, HCT116 WILDTYPE CELLS: {len(WTst_ids)}\n",
    "\n",
    "Looking at the number of differentially expressed transcripts by delta-rank > 100 metric in each cell type, we\n",
    "get:\n",
    "   U2OS --> DLD1 {WTst_differential_expression_count.loc[\"U2OS_WT\",\"DLD1_WT\"]}\n",
    "   U2OS --> HTC116 {WTst_differential_expression_count.loc[\"U2OS_WT\",\"HCT116_WT\"]}\n",
    "   DLD1 --> HCT116 {WTst_differential_expression_count.loc[\"DLD1_WT\",\"HCT116_WT\"]}\n",
    "   \n",
    "Counts of differentially expressed transcripts in each cell type.\n",
    "\n",
    "Looking at experiment type changes, we find \n",
    "   U2OS_WT --> U2OS_NFKB_KO {WTst_differential_expression_count.loc[\"U2OS_WT\",\"U2OS_NFKB\"]}\n",
    "   HCT116_WT --> HCT116_GEM {WTst_differential_expression_count.loc[\"HCT116_WT\",\"HCT116_GEM\"]}\n",
    "      \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do enhancer regions exhibit differential activity in the cell types under study? ###\n",
    "We had previously identified separate groups of top5% enhancers in each cell type under study. Furthermore, we observed that the groups of top5% enhancers were different for each of the cell types. To define APOBEC-on activators, we took an intersection of the top5% enhancers. To study differential expression in these cell types, we defined a new set of APOBEC-sometimes enhancer regions consisting of the union of top5% enhancer oligos in each of these experiments. \n",
    "\n",
    "There were [XXX] total enhancer locations in this set. For each enhancer, we examined the descending rank-sorted order of that enhancer in the experimental data for that locus, assigning a number equal to the absolute value of that rank sort-order difference in each set to each of the APOBEC-somstetimes enhancer regions. Looking at the full set of APOBEC-sometimes enhancer regions, we found a mean ranksort discrepancy of [XXX] between the two data sets. To quantify significance of this number, we also computed the mean ranksort discrepancy of the APOBEC-sometimes enhancers in each of the two experimental replicates of DLD1 and U2OS. We found that the average absolute ranksort differential of APOBEC-sometimes enhancer candidates was [XXX] and [XXX] in the DLD1 and U2OS replicates respectively, with an overall mean of [XXX] and overall standard deviation of [XXX]. We set a threshold of [XXX], which was the mean discrepancy + 1 STD as the ranksort discrepancy to define a given enhancer oligo as differentially activating between the two cell types and found that amongst the [XXX] oligos in APOBEC-sometimes, [XXX] ([XXX]%) “APOBEC-differential-activators”, were differentially expressed by this measure.\n",
    "\n",
    "Starting from this measure of differential expression in wild-type cells that were highly expressive of APOBEC, we sought to apply the same measure to quantification of differential expression between the APOBEC-expressing cell lines and the HCT116 cell type which does not natively express APOBEC. Defining an inclusive set of enhancers, WILDTYPE-activators with [XXX] members, consisting of the top5% enhancers from DLD1, HCT116, and U2OS, we looked at differential expression, computed between all 3x3 cell types for each of these enhancers. We were also curious to see how differential expression of the bot5% would vary between these three cell types and therefore defined the set WILDTYPE-repressors and computed the same score, using all 3x3 comparisons.\n",
    "\n",
    "Using the same definitions above, we computed average and std deviation of ranksort discrepancies for activators ( [XXX]mean, [XXX]stddev ) and repressors  ( [XXX]mean, [XXX]stddev )  individually and identified as differentially expressed all those oligos which crossed the threshold of mean + 1 std discrepancy change. By this measure, we found that [XXX] / ([XXX]) oligos were differentially expressed between either DLD1 / (U2OS) and HCT116 cells respectively. We called their intersection, the “APOBEC-on-enhancers” (XXX regions). Comparing the set of oligos previously identified as in the DLD1 and U2OS sets but not in HCT116 cells (“ABOPEC-exclusive” oligos), we found that [XXX]% of APOBEC-exclusive oligos were found in this set of differentially expressed oligos, confirming the internal consistency of these two measures. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffex = exptypes.apply(lambda ct1: \n",
    "        exptypes.apply(lambda ct2:\n",
    "            obe_wtst.loc[lambda x:(x[ct1 + \"_rank\"]  - x[ct2+\"_rank\"]) > 100].oligo.unique())).stack()\\\n",
    "    .groupby(level=[0,1]).apply(lambda x:pd.Series([e for i,e in enumerate(x.values[0])]))\n",
    "\n",
    "diffex = diffex.rename(\"oligo\").reset_index(level=2,drop=True)\n",
    "diffex = diffex.rename_axis([\"expressed\",\"unexpressed\"]).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZERO AREA FILTERING #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obe = oligos_by_exp.reset_index().loc[lambda x:x.mutant_num<5].groupby([\"starts\",\"mutant_num\",\"exp_type\"]).mu.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = pd.concat(\n",
    "    [all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([(df.values[ofs:ofs+4,:] * (\n",
    "        np.concatenate([\n",
    "            (np.zeros((4,1))+1),\n",
    "            np.fliplr(1 - np.diag([1,1,1,1]))],\n",
    "        axis=1))\n",
    "               ).sum()  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"allothers\") / 16,\n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([(df.values[ofs:ofs+4,:] * (\n",
    "        np.concatenate([\n",
    "            (np.zeros((4,1))),\n",
    "            np.fliplr( np.diag([1,1,1,1]))],\n",
    "        axis=1))\n",
    "               ).sum()  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"onlyablations\") / 4,\n",
    "     \n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([\n",
    "        (df.values[ofs:ofs+5,:][np.nonzero(\n",
    "                       1-np.array(\n",
    "                          [[0,0,0,0,1],\n",
    "                           [0,0,0,1,1],\n",
    "                           [0,0,1,1,0],\n",
    "                           [0,1,1,0,0],\n",
    "                           [0,1,0,0,0]]))]\n",
    "               ).sum()   \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"allothers2\") / 17,\n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([np.std(df.values[ofs:ofs+4,:][np.nonzero (\n",
    "        np.concatenate([\n",
    "            (np.zeros((4,1))+1),\n",
    "            np.fliplr(1 - np.diag([1,1,1,1]))],\n",
    "        axis=1))\n",
    "                                             ])\n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"allothersstd\"),\n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([np.std(df.values[ofs:ofs+4,:])  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"std\"),\n",
    "         all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([\n",
    "        (df.values[ofs:ofs+5,:][np.nonzero(\n",
    "                       np.array([[0,0,0,0,1],\n",
    "                       [0,0,0,1,1],\n",
    "                       [0,0,1,1,0],\n",
    "                       [0,1,1,0,0],\n",
    "                       [0,1,0,0,0]]))]\n",
    "               ).sum()  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"onlyablations2\") / 8,\n",
    "          all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([(df.values[ofs:ofs+4,:] * (\n",
    "        np.concatenate([\n",
    "            (np.zeros((4,1))),\n",
    "            np.fliplr(1 - np.diag([1,1,1,1]))],\n",
    "        axis=1))\n",
    "               ).sum()  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"othermutants\") / 12,\n",
    "     \n",
    "          all_obe.unstack(level=1).groupby(level=1).apply(\n",
    "    lambda df:\n",
    "    pd.Series([(df.values[ofs:ofs+4,:] * (\n",
    "        np.concatenate([\n",
    "            (np.zeros((4,1))+1),\n",
    "            np.fliplr(0* np.diag([1,1,1,1]))],\n",
    "        axis=1))\n",
    "               ).sum()  \n",
    "        for ofs in range(len(df.values) - 4)],index = df.index[4:])\n",
    ").rename(\"onlywildtype\") / 4,\n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(lambda df:\n",
    "                                                \n",
    "       pd.Series([ks_2samp( df.values[ofs:ofs+4,:][np.nonzero(   np.concatenate([\n",
    "            (np.zeros((4,1))+1),\n",
    "            np.fliplr(1-np.diag([1,1,1,1]))],\n",
    "        axis=1))] ,\n",
    "                 df.values[ofs:ofs+4,:][np.nonzero(  np.concatenate([\n",
    "            (np.zeros((4,1))+0),\n",
    "            np.fliplr(np.diag([1,1,1,1]))],\n",
    "        axis=1))])[1]\n",
    "          for ofs in range(len(df.values) - 4)],index = df.index[4:])).rename(\"ks_pval\"),\n",
    "     \n",
    "          all_obe.unstack(level=1).groupby(level=1).apply(lambda df:\n",
    "                                                \n",
    "       pd.Series([ks_2samp( df.values[ofs:ofs+5,:][np.nonzero(\n",
    "                       np.array([[0,0,0,0,1],\n",
    "                       [0,0,0,1,1],\n",
    "                       [0,0,1,1,0],\n",
    "                       [0,1,1,0,0],\n",
    "                       [0,1,0,0,0]]))],\n",
    "           df.values[ofs:ofs+5,:][np.nonzero(\n",
    "                       1- np.array([[0,0,0,0,1],\n",
    "                       [0,0,0,1,1],\n",
    "                       [0,0,1,1,0],\n",
    "                       [0,1,1,0,0],\n",
    "                       [0,1,0,0,0]]))]\n",
    "       )[1]\n",
    "          for ofs in range(len(df.values) - 4)],index = df.index[4:])).rename(\"ks2_pval\"),\n",
    "     \n",
    "     \n",
    "     all_obe.unstack(level=1).groupby(level=1).apply(lambda df:\n",
    "                                                \n",
    "       pd.Series([ks_2samp( df.values[ofs:ofs+4,:][np.nonzero(   np.concatenate([\n",
    "            (np.zeros((4,1))+1),\n",
    "            np.fliplr(1-np.diag([1,1,1,1]))],\n",
    "        axis=1))] ,\n",
    "                 df.values[ofs:ofs+4,:][np.nonzero(  np.concatenate([\n",
    "            (np.zeros((4,1))+0),\n",
    "            np.fliplr(np.diag([1,1,1,1]))],\n",
    "        axis=1))])[0]\n",
    "          for ofs in range(len(df.values) - 4)],index = df.index[4:])).rename(\"ks_stat\")\n",
    "    ],axis = 1).reset_index(level=2, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.index.names = [\"exp_type\",\"starts\"]\n",
    "filters[\"actual_starts\"] = filters.index.get_level_values(\"starts\") + 30\n",
    "filters = filters.reset_index(level=1, drop = True).set_index(\"actual_starts\",append=True)\n",
    "filters.index.names = [\"exp_type\",\"mutant_start_position\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters[\"mutdiff\"] = filters[\"othermutants\"] - filters[\"onlyablations\"]\n",
    "filters[\"wtdiff\"] = filters[\"onlywildtype\"] - filters[\"onlyablations\"]\\\n",
    "\n",
    "filters[\"othersdiff\"] = filters[\"allothers\"] - filters[\"onlyablations\"]\n",
    "filters[\"rank_mutdiff\"] = filters[[\"mutdiff\"]].join(\n",
    "        filters[[\"mutdiff\"]].groupby(\"mutant_start_position\").mean().reset_index().sort_values(\"mutdiff\",ascending = False).reset_index().rename_axis(\"rank\",axis=\"index\").reset_index().set_index([\"mutant_start_position\"])[\"rank\"],\n",
    "    on=\"mutant_start_position\")[\"rank\"]\n",
    "filters[\"rank_ao\"] = filters[[\"othersdiff\"]].join(\n",
    "        filters[[\"othersdiff\"]].groupby(\"mutant_start_position\").mean().reset_index().sort_values(\"othersdiff\",ascending = False).reset_index().rename_axis(\"rank\",axis=\"index\").reset_index().set_index([\"mutant_start_position\"])[\"rank\"],\n",
    "    on=\"mutant_start_position\")[\"rank\"]\n",
    "filters[\"rank_ao_dld1\"] = filters[[\"othersdiff\"]].loc[lambda x: x.index.get_level_values(0).str.contains(\"DLD\")].join(\n",
    "        filters[[\"othersdiff\"]].groupby(\"mutant_start_position\").mean().reset_index().sort_values(\"othersdiff\",ascending = False).reset_index().rename_axis(\"rank\",axis=\"index\").reset_index().set_index([\"mutant_start_position\"])[\"rank\"],\n",
    "    on=\"mutant_start_position\")[\"rank\"]\n",
    "filters[\"rank_ao_u2os\"] = filters[[\"othersdiff\"]].loc[lambda x: x.index.get_level_values(0).str.contains(\"U2OS\")].join(\n",
    "        filters[[\"othersdiff\"]].groupby(\"mutant_start_position\").mean().reset_index().sort_values(\"othersdiff\",ascending = False).reset_index().rename_axis(\"rank\",axis=\"index\").reset_index().set_index([\"mutant_start_position\"])[\"rank\"],\n",
    "    on=\"mutant_start_position\")[\"rank\"]\n",
    "filters[\"rank_ao_hct116\"] = filters[[\"othersdiff\"]].loc[lambda x: x.index.get_level_values(0).str.contains(\"HCT\")].join(\n",
    "        filters[[\"othersdiff\"]].groupby(\"mutant_start_position\").mean().reset_index().sort_values(\"othersdiff\",ascending = False).reset_index().rename_axis(\"rank\",axis=\"index\").reset_index().set_index([\"mutant_start_position\"])[\"rank\"],\n",
    "    on=\"mutant_start_position\")[\"rank\"]\n",
    "\n",
    "\n",
    "filters[\"filterchange\"] = np.max(\n",
    "    [(filters.onlyablations - filters.allothers),\n",
    "     (filters.onlyablations2 - filters.allothers2)]\n",
    ")\n",
    "filters[\"ks_1or2\"] = filters.apply(lambda x: (x.ks_pval < .05) | (x.ks2_pval < .05),axis =1)\n",
    "filters[\"log_ks_pval\"] = np.log(filters.ks_pval)\n",
    "filters_hq = filters.loc[lambda x: x.ks_1or2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.reset_index(level=0).loc[300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHICH 30BP REGIONS PASS THE ZERO AREA FILTER & HAVE WT EXPRESSION LEVELS FALLING INTO THE TOP 5%? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals = [.75,.8,.85,.9,.95,.98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = pd.DataFrame()\n",
    "quantile_counts = pd.DataFrame()\n",
    "\n",
    "for quantile in qvals:\n",
    "    these_filters = filters_hq.copy()\n",
    "    \n",
    "    wt_quantile = quantile\n",
    "    ablation_quantile = quantile\n",
    "    change_quantile = quantile\n",
    "\n",
    "    #USES ALL EXPRESSION VALUES\n",
    "    mubar_wt_cutoffs = filters.groupby(\"exp_type\").onlywildtype.quantile(wt_quantile)\n",
    "    mubar_ablation_cutoffs = filters.groupby(\"exp_type\").onlyablations.quantile(ablation_quantile)\n",
    "\n",
    "    these_filters[\"filterchange\"] =  these_filters.apply(lambda x:\n",
    "                                                       np.max(np.abs([x.onlyablations - x.allothers,\n",
    "                                                               x.onlyablations2 - x.allothers2,])),axis=1)\n",
    "    filter_change_cutoff = these_filters.filterchange.groupby(\"exp_type\").quantile(change_quantile)\n",
    "\n",
    "    print(f\"\"\"wt_cutoff quantile /   change_cutoff mean quantile  {quantile} == {mubar_wt_cutoffs.mean()} {quantile} == {filter_change_cutoff.mean()}\"\"\")\n",
    "\n",
    "\n",
    "    these_filters[\"ablation_mu_filtered\"] = these_filters.apply(\n",
    "        lambda y:(1 if \n",
    "                  (y.onlyablations > mubar_ablation_cutoffs.loc[y.name[0]]) &\n",
    "                    (y.onlyablations > y.onlywildtype) else 0),axis=1)\n",
    "    \n",
    "    these_filters[\"wt_filtered\"] = these_filters.apply(lambda y:(1 if\n",
    "                 (y.onlywildtype > mubar_wt_cutoffs.loc[y.name[0]]) &\n",
    "                    (y.onlywildtype > y.onlyablations) else 0),axis=1)\n",
    "                                                                 \n",
    "                                                                 \n",
    "    these_filters[\"change_filtered\"] = these_filters.apply(lambda y:(1 if (y.filterchange > filter_change_cutoff.loc[y.name[0]]) else 0),axis=1)\n",
    "    these_filters[\"both_filtered\"] = these_filters.wt_filtered * these_filters.change_filtered\n",
    "    these_filters[\"both_ablation_filtered\"] = these_filters.ablation_mu_filtered * these_filters.change_filtered\n",
    "\n",
    "    these_filters[\"filter_color\"] = these_filters.apply(\n",
    "        lambda x:(6 if (x.both_filtered  and x.both_ablation_filtered)\n",
    "                   else(5 if x.both_ablation_filtered\n",
    "                        else(4 if x.ablation_mu_filtered\n",
    "                             else(3 if x.both_filtered\n",
    "                                   else(2 if x.change_filtered \n",
    "                                        else (1 if x.wt_filtered \n",
    "                                              else 0) ))))),axis=1)\n",
    "\n",
    "    quantiles = quantiles.append(these_filters.assign(quantile = quantile))\n",
    "    out = pd.Series([1,2,3]).apply(lambda n:(these_filters[\"filter_color\"].loc[lambda x:x>0].unstack(level=0).fillna(0) == n).sum()).assign(quantile = quantile)\n",
    "    quantile_counts =quantile_counts.append(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,subs = plt.subplots(1,quantiles[\"quantile\"].nunique())\n",
    "\n",
    "\n",
    "f.set_size_inches(10,12)\n",
    "for i,q in enumerate(sorted(quantiles[\"quantile\"].unique())):\n",
    "    plt.sca(subs[i])\n",
    "    data = quantiles.loc[lambda df:df[\"quantile\"]==q]\n",
    "    sns.heatmap( data = (data[\"filter_color\"]*(data[\"ks_pval\"]<.1)).loc[lambda x:x>0].unstack(level=0).fillna(0))\n",
    "\n",
    "    #plt.sca(subs[i*2+1])\n",
    "    #sns.heatmap(data[\"log_ks_pval\"].loc[lambda x:x<-2].unstack(level=0).fillna(0))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs are found in motif activator / repressor candidates? ###\n",
    "In the above section, we identified the 30 base pair mutations which had a statistically significant differential expression compared to the combined set of overlapping wild type and mutant oligos. Now, we are interested in joining this data with the motif hit information computed above to identify candidate motifs influencing expression levels. Note that the p values for mutants above treat activation and repression equivalently, therefore this step will identify both candidate activators and candidate repressors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute candidate mutation start positions for each motif\n",
    "# note that right now if a motif has multiple possible start positions, this will\n",
    "# only look at the first\n",
    "\n",
    "mutant_positions_idx = pd.Index(oligos.mutant_start.unique()).sort_values()\n",
    "motif_position_idxs = motif_oligos_data.position.apply(lambda x:mutant_positions_idx.searchsorted(x)-1)\n",
    "motif_positions = motif_position_idxs.apply(lambda x: mutant_positions_idx[x])\n",
    "motif_oligos_data[\"target_mutant_start_position\"] = motif_positions\n",
    "\n",
    "# join the motif hits with mutation data, accepting only hits which fall above a given affine score\n",
    "# later in the process, we will model affine scores using a statistical model\n",
    "\n",
    "affine_scores = [0,1,2,3,5]\n",
    "qjoin_afs = pd.concat([\n",
    " pd.merge(\n",
    "    quantiles.reset_index(),\n",
    "    motif_oligos_data.dropna(subset =[\"target_mutant_start_position\"]).loc[lambda x: x.affine_score > afs],\n",
    "    right_on=\"target_mutant_start_position\",\n",
    "    left_on=\"mutant_start_position\").assign(affine_score_threshold = afs)\n",
    "    \n",
    "    for afs in affine_scores],axis=0)\n",
    "                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qjoin_afs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs instances falling in 30 BP enhancer candidates are significant above each threshold value? ###\n",
    "Using the definitions of affine motif log odds scores for the instances identified above, compute the total number of motif hits which are identified overall at that significance range. These numbers will be used in the next step to evaluate the overall enrichment fractions of those instances which are identified in mutants of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focusing on the subset of motif instances with a basal affine score of zero, compute the total number of\n",
    "# hits which fall in mutation regions found in the above step\n",
    "\n",
    "motif_hits_of_interest = motif_oligos_data.loc[lambda x: x.affine_score > 0]\n",
    "motif_filter_color_counts = pd.DataFrame()\n",
    "\n",
    "for q in quantiles[\"quantile\"].unique():\n",
    "    qsel = qjoin_afs.loc[lambda x: x[\"quantile\"] == q] \n",
    "    temp = qsel.groupby(['jaspar_id','exp_type',\"affine_score_threshold\"]).filter_color.value_counts().rename(\"fc_count\")\n",
    "    affine_total_hit_counts = temp.reset_index().set_index(\"affine_score_threshold\").groupby(\"affine_score_threshold\").apply(lambda x: x.set_index('jaspar_id')\\\n",
    "                                                           .join(motif_hits_of_interest.loc[lambda y:y.affine_score>x.name]\\\n",
    "                                                                 .groupby(['jaspar_id']).size().rename(\"n_total_hits\")))           \n",
    "\n",
    "    \n",
    "    motif_filter_color_counts = motif_filter_color_counts.append(\n",
    "        temp.reset_index().set_index(\"affine_score_threshold\").groupby(\"affine_score_threshold\").apply(lambda x: x.set_index('jaspar_id')\\\n",
    "                                                           .join(motif_hits_of_interest.loc[lambda y:y.affine_score>x.name]\\\n",
    "                                                                 .groupby(['jaspar_id']).size().rename(\"n_total_hits\")))\\\n",
    "               .reset_index().set_index([\"jaspar_id\",\"exp_type\",\"affine_score_threshold\", \"filter_color\"]).assign(quantile=q))\n",
    "    \n",
    "motif_filter_color_counts = motif_filter_color_counts.set_index(\"quantile\",append=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs have the highest % of instances falling in interesting regions? ###\n",
    "Before moving on, we were interested in ranking motifs by the fraction of instances falling interesting regions overall. This will provide a consistent axis for future plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_fcc_selected =  \\\n",
    "    motif_filter_color_counts.reset_index().loc[lambda x: (x[\"quantile\"] ==.75) & (x[\"affine_score_threshold\"] ==0)]\n",
    "jaspar_overall_frac_interesting = (motif_fcc_selected.loc[lambda x:x.filter_color>0].groupby(\"jaspar_id\").fc_count.sum()/\\\n",
    "    motif_fcc_selected.groupby(\"jaspar_id\").fc_count.sum()).fillna(0).rename(\"fraction_interesting\")\n",
    "jaspar_overall_rank = jaspar_overall_frac_interesting.reset_index().sort_values(\"fraction_interesting\",ascending=False)\\\n",
    "    .reset_index().set_index(\"jaspar_id\")[\"index\"].rename(\"motif_rank_index\")\n",
    "motif_filter_color_counts = motif_filter_color_counts.join(jaspar_overall_rank,on=\"jaspar_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What fraction of each jaspar motif are interesting according to various measures? ###\n",
    "Motif instances can be interesting because they correspond to (1) highly expressed oligos, (2) differentially expressed oligos, or (3) both. Set (3) will be the principal focus of future sections when we look for activator motifs, however set (2) will be useful when we look for repressors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_motif_enriched6 = (motif_filter_color_counts.reset_index(\"filter_color\").groupby([\"jaspar_id\",\"exp_type\",\"affine_score_threshold\",\"quantile\"])\\\n",
    "    .apply(lambda x:  x.set_index(\"filter_color\").loc[6].fc_count.sum() if (6 in x.filter_color.values )  else 0 ) /\\\n",
    "        motif_filter_color_counts.reset_index(level=4).n_total_hits.loc[~motif_filter_color_counts.reset_index(level=4).index.duplicated()])\\\n",
    "            .rename(\"color_6_enrichment\")\n",
    "\n",
    "frac_motif_enriched5 = (motif_filter_color_counts.reset_index(\"filter_color\").groupby([\"jaspar_id\",\"exp_type\",\"affine_score_threshold\",\"quantile\"])\\\n",
    "    .apply(lambda x:  x.set_index(\"filter_color\").loc[5].fc_count.sum() if (5 in x.filter_color.values )  else 0 ) /\\\n",
    "        motif_filter_color_counts.reset_index(level=4).n_total_hits.loc[~motif_filter_color_counts.reset_index(level=4).index.duplicated()])\\\n",
    "            .rename(\"color_5_enrichment\")\n",
    "\n",
    "frac_motif_enriched4 = (motif_filter_color_counts.reset_index(\"filter_color\").groupby([\"jaspar_id\",\"exp_type\",\"affine_score_threshold\",\"quantile\"])\\\n",
    "    .apply(lambda x:  x.set_index(\"filter_color\").loc[4].fc_count.sum() if (4 in x.filter_color.values )  else 0 ) /\\\n",
    "        motif_filter_color_counts.reset_index(level=4).n_total_hits.loc[~motif_filter_color_counts.reset_index(level=4).index.duplicated()])\\\n",
    "            .rename(\"color_4_enrichment\")\n",
    "\n",
    "frac_motif_enriched3 = (motif_filter_color_counts.reset_index(\"filter_color\").groupby([\"jaspar_id\",\"exp_type\",\"affine_score_threshold\",\"quantile\"])\\\n",
    "    .apply(lambda x:  x.set_index(\"filter_color\").loc[3].fc_count.sum() if (3 in x.filter_color.values )  else 0 ) /\\\n",
    "        motif_filter_color_counts.reset_index(level=4).n_total_hits.loc[~motif_filter_color_counts.reset_index(level=4).index.duplicated()])\\\n",
    "            .rename(\"color_3_enrichment\")\n",
    "\n",
    "frac_motif_enriched2 = (motif_filter_color_counts.reset_index(\"filter_color\").groupby([\"jaspar_id\",\"exp_type\",\"affine_score_threshold\",\"quantile\"])\\\n",
    "    .apply(lambda x:  x.set_index(\"filter_color\").loc[2].fc_count.sum() if (2 in x.filter_color.values )  else 0 ) /\\\n",
    "        motif_filter_color_counts.reset_index(level=4).n_total_hits.loc[~motif_filter_color_counts.reset_index(level=4).index.duplicated()])\\\n",
    "            .rename(\"color_2_enrichment\")\n",
    "\n",
    "frac_motif_enriched1 = (motif_filter_color_counts.reset_index(\"filter_color\").groupby([\"jaspar_id\",\"exp_type\",\"affine_score_threshold\",\"quantile\"])\\\n",
    "    .apply(lambda x:  x.set_index(\"filter_color\").loc[1].fc_count.sum() if (1 in x.filter_color.values )  else 0 ) /\\\n",
    "        motif_filter_color_counts.reset_index(level=4).n_total_hits.loc[~motif_filter_color_counts.reset_index(level=4).index.duplicated()])\\\n",
    "            .rename(\"color_1_enrichment\")\n",
    "\n",
    "ordered_cols = [\"jaspar_id\",  \"exp_type\",   \"affine_score_threshold\",  \"quantile\", \"filter_color\"]\n",
    "motif_filter_color_counts = motif_filter_color_counts.join(frac_motif_enriched1, on =ordered_cols)\\\n",
    "    .join(frac_motif_enriched2, on =ordered_cols)\\\n",
    "    .join(frac_motif_enriched3, on =ordered_cols)\\\n",
    "    .join(frac_motif_enriched4, on =ordered_cols)\\\n",
    "    .join(frac_motif_enriched5, on =ordered_cols)\\\n",
    "    .join(frac_motif_enriched6, on =ordered_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCT_CANDIDATES = motif_filter_color_counts.reset_index().\\\n",
    "    loc[lambda df: df.exp_type.isin([\"U2OS_WT\",\"U2OS_NFKB\",\"HCT116_WT\",\"HCT116_GEM\",\"DLD1_WT\"])].\\\n",
    "    loc[lambda df: (df[\"quantile\"] == .95) & (df[\"affine_score_threshold\"] == 2)  & (df[\"filter_color\"] == 3)]\n",
    "HCT_CANDIDATES.set_index([\"exp_type\",\"jaspar_id\"]).color_3_enrichment.unstack().T.join(jaspar.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,subs = plt.subplots(1,3,sharey = True)\n",
    "f.set_size_inches(12,4)\n",
    "f.suptitle(\"number of hits corresponding to each filter type for all jaspar motifs\",y=1.05)\n",
    "\n",
    "for e in range(1,4):\n",
    "    plt.sca(subs[e-1])\n",
    "    sns.scatterplot( x = \"n_total_hits\", y = \"fc_count\",alpha=.5,\n",
    "                    data =motif_filter_color_counts.reset_index().loc[lambda x:(x[\"quantile\"]==.95 ) &( x[\"filter_color\"]==e )& (x.exp_type==\"U2OS_WT\")],\n",
    "                    )\n",
    "    plt.gca().set_title(f\"counts of filter {e} vs total counts\")\n",
    "    \n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs are of interest for further investigation? ###\n",
    "Having computed a set of motif statistics, most important the number and fraction of motif instances having an affine score greater than a threshold value which show up transcripts exhibiting high levels of basal expression + differential mutant expression. For this experiment, we use the 90% percent quantile, which means that all quantities, including:\n",
    " 1. wildtype mubar cutoffs\n",
    " 2. ablation mubar cutoffs\n",
    " 3. absolute value differential expression cutoffs\n",
    "\n",
    "Are labeled as \"on\" when they fall in 90th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_quantile =.95\n",
    "base_afs = 0\n",
    "\n",
    "motifs_of_interest = motif_filter_color_counts.reset_index()\\\n",
    "    .loc[lambda x:(x[\"quantile\"] ==base_quantile) & (x[\"affine_score_threshold\"] == base_afs) & \n",
    "         ((x[\"color_1_enrichment\"]+x[\"color_2_enrichment\"]+x[\"color_3_enrichment\"]+\n",
    "          x[\"color_4_enrichment\"]+x[\"color_5_enrichment\"]+x[\"color_6_enrichment\"]) > 0) ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which motifs are of interest in each cell type by the above definition? ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp =motifs_of_interest.reset_index()\\\n",
    "    .loc[lambda x:x.affine_score_threshold==base_afs]\\\n",
    "    .loc[lambda x:x[\"quantile\"]==base_quantile]\\\n",
    "    .set_index([\"jaspar_id\",\"exp_type\",\"filter_color\"]).filter(regex=\"color_\\d_enrichment\")\\\n",
    "    .reset_index(\"filter_color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = motifs_of_interest.reset_index()\\\n",
    "    .loc[lambda x:x.affine_score_threshold==base_afs]\\\n",
    "    .loc[lambda x:x[\"quantile\"]==base_quantile]\\\n",
    "    .set_index([\"jaspar_id\",\"exp_type\",\"filter_color\"])\\\n",
    "    .reset_index(\"filter_color\").loc[lambda x:~x.index.duplicated()].filter(regex=\"color_\\d_enrichment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = plt.gcf()\n",
    "ax = plt.gca()\n",
    "ax.set_title(f\"\"\"% of motif instances identified at score level {base_afs} falling in various enrichment categories.\n",
    "Colors 1 & 4 are expression level filters. Color 2 is fold change filtered. \n",
    "Colors 3 and 5 are enrichments of fold change and WT / ABLATION mu respectively.\"\"\")\n",
    "f.set_size_inches(16,3)\n",
    "sns.heatmap(colors.T>0,square=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors.columns.name=\"color_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(colors.unstack(\"exp_type\").fillna(0).T.reset_index().set_index([\"exp_type\",\"color_name\"]).sort_index() > 0,square =True,cbar=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs behave as activators and which behave as repressors? ###\n",
    "Using the \"colors\" map above, we focus on motif types (color_3) and (color_5), having instances which both exhibit a significant fold expression change (fold change pval threshold defined by quantiles, above) and an enrichment of expression in either wild type or mutant oligos. We will initially compute the analysis using the base affine p value, to determine which motifs have --any-- instances in either category, and then make a plot which for each motif, computes the STD of affine p value and plots the fraction of motifs falling above threshold for instances at each z-score.\n",
    "\n",
    "We will begin this analysis by taking a max over all experiment types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors_by_color_exp = colors.unstack(\"exp_type\").fillna(0).T.reset_index().set_index([\"exp_type\",\"color_name\"])\n",
    "colors_by_color = colors_by_color_exp.groupby(\"color_name\").max()\n",
    "c3 = colors_by_color.T.color_3_enrichment\n",
    "c5 = colors_by_color.T.color_5_enrichment\n",
    "\n",
    "c3_vals = c3.loc[c3>0].rename(\"c3_vals\")\n",
    "c5_vals = c5.loc[c5>0].rename(\"c5_vals\")\n",
    "\n",
    "activator_ids = set(c3_vals.loc[lambda x: x>0].index.unique())\n",
    "repressor_ids = set(c5_vals.loc[lambda x: x>0].index.unique())\n",
    "\n",
    "print(f\"\"\"\n",
    "Identified subsets of activator and repressor motifs.\n",
    "\n",
    "n_activators {len(activator_ids)}\n",
    "n_repressors {len(repressor_ids)}\n",
    "n_both {len(set(activator_ids).intersection(repressor_ids))}\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking more deeply into the motifs of interest, what are the are the std and means of their affine scores? ####\n",
    "Having identified candidate motifs of interest in the step above, we now which to pick specific instances that will be subject to further investigation. To do this, we compute that distributions of affine scores for each motif. These will be used to compute the significance of each motif hit identified above. From the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,subs = plt.subplots(1,2)\n",
    "f.set_size_inches(12,3)\n",
    "plt.sca(subs[0])\n",
    "sns.lineplot(x = \"affine_score_threshold\", y=\"color_3_enrichment\", hue=\"jaspar_id\",\n",
    "             data = motif_filter_color_counts.reset_index().loc[\n",
    "    lambda x: (x[\"quantile\"] ==.75) & x.jaspar_id.isin(activator_ids)])\n",
    "\n",
    "plt.sca(subs[1])\n",
    "sns.lineplot(x = \"affine_score_threshold\", y=\"color_5_enrichment\", hue=\"jaspar_id\",\n",
    "             data = motif_filter_color_counts.reset_index().loc[\n",
    "    lambda x: (x[\"quantile\"] ==.75) & x.jaspar_id.isin(repressor_ids)])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_score_stats = motif_hits_of_interest.groupby(\"jaspar_id\").apply(lambda x: pd.Series({\"score_std\":x.affine_score.std(),\"score_mean\":x.affine_score.mean()}))\n",
    "\n",
    "mod_withscores = motif_oligos_data.join(motif_score_stats,on=\"jaspar_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "motif_score_stats = motif_hits_of_interest.groupby(\"jaspar_id\").apply(lambda x: pd.Series({\"score_std\":x.affine_score.std(),\"score_mean\":x.affine_score.mean()}))\n",
    "\n",
    "affine_stds = [0,.25,.5,1,2,3]\n",
    "qjoin_afs = pd.concat([\n",
    " pd.merge(\n",
    "    quantiles.reset_index(),\n",
    "    mod_withscores.dropna(subset =[\"target_mutant_start_position\"])\\\n",
    "     .loc[lambda x: x.affine_score > (x.score_mean+x.score_std*afstd)],\n",
    "    right_on=\"target_mutant_start_position\",\n",
    "    left_on=\"mutant_start_position\").assign(affine_zscore_threshold = afstd)\n",
    "    \n",
    "    for afstd in affine_stds],axis=0)\n",
    "\n",
    "\n",
    "qsel = qjoin_afs.loc[lambda x: x[\"quantile\"] == base_quantile] \n",
    "temp = qsel.groupby(['jaspar_id','exp_type',\"affine_zscore_threshold\"]).filter_color.value_counts().rename(\"fc_count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_total_zs_counts = temp.reset_index().set_index(\"affine_zscore_threshold\").groupby(\"affine_zscore_threshold\").apply(lambda x: x.set_index('jaspar_id')\\\n",
    "                                                           .join(motif_hits_of_interest.loc[lambda y:y.affine_score>x.name]\\\n",
    "                                                                 .groupby(['jaspar_id']).size().rename(\"n_total_hits\")))           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = dict([[l,chrseq[region_bounds[0]:region_bounds[1]].count(l) / len(chrseq[region_bounds[0]:region_bounds[1]])] for l in \"ATGC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load motifs\n",
    "from Bio.motifs import jaspar as mjaspar\n",
    "import Bio.motifs\n",
    "from Bio import motifs as bmotifs\n",
    "with open(\"../data/jaspar.pfm\") as handle:\n",
    "    jaspar_motifs = mjaspar._read_jaspar(handle)\n",
    "\n",
    "for j in jaspar_motifs:\n",
    "     j.pseudocounts =1   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists =   pd.Series({aid:jaspar_motifs[aid].pssm.distribution(background=background)for aid in activator_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaspar_fdrs = pd.concat([\n",
    "    pd.Series(v).rename(k)\n",
    "    for k,v in {\n",
    "    \"fdr_001\":dists.apply(lambda d: d.threshold_fpr(.001)),\n",
    "        \"fdr_002\":dists.apply(lambda d: d.threshold_fpr(.002)),\n",
    "        \"fdr_005\":dists.apply(lambda d: d.threshold_fpr(.005)),\n",
    "        \"fdr_01\":dists.apply(lambda d: d.threshold_fpr(.01)),\n",
    "        \"fdr_02\":dists.apply(lambda d: d.threshold_fpr(.02)),\n",
    "        \"fdr_05\":dists.apply(lambda d: d.threshold_fpr(.05)),\n",
    "}.items()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_hits_by_jid_start= motif_hits_of_interest.set_index([\"jaspar_id\",\"position\"]).sort_index(level=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activator_motif_hits = motif_hits_of_interest.drop_duplicates([\"jaspar_id\",\"position\"]).set_index([\"jaspar_id\",\"position\"]).loc[pd.Index(jaspar_fdrs.index)].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaspar_fdrs.index.name = \"jaspar_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import IndexSlice as idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = 131\n",
    "fscore = jaspar_fdrs.loc[mid].fdr_005\n",
    "quantiles_sorted = quantiles.sort_index()\n",
    "#motif_hits_by_jid_start.loc[131].loc[lambda x:x.score > fscore].target_mutant_start_position.apply(lambda x:quantiles_sorted.loc[((idx[:],idx[x]),idx[:])])\n",
    "\n",
    "quantiles_u2os = quantiles.loc[\"U2OS_WT\"].sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a total instance count for each fdr threshold\n",
    "jid_counts_at_threshold = jaspar_fdrs.apply( \n",
    "    lambda j: j.apply(\n",
    "        lambda f:len(motif_hits_by_jid_start.loc[j.name].loc[lambda x:x.score > f].loc[lambda x: ~x.index.duplicated()])),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_sorted_indexed =quantiles_sorted.reset_index().set_index([\"mutant_start_position\",\"exp_type\",\"filter_color\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_counts = quantiles_sorted.loc[lambda x: x[\"quantile\"]==base_quantile].groupby(level=[0,1]).apply(lambda x: x.groupby(\"filter_color\").size()).rename(\"fc_counts\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcc_deindex = fc_counts.reset_index(level=[0,2]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fdr_level_counts =jaspar_fdrs.apply(lambda x:x.apply( lambda f: motif_hits_by_jid_start.loc[lambda x: ~x.index.duplicated()].loc[x.name].loc[lambda y:y.score > f]\\\n",
    "                                        .join(fcc_deindex, on =\"target_mutant_start_position\",how=\"inner\")\\\n",
    "                                        .groupby([\"filter_color\",\"exp_type\"]).size()).unstack(\"filter_color\")\n",
    "                  ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tightest_3_thrs = fdr_level_counts[3,\"U2OS_WT\"].apply(lambda x: x.idxmin(x.notna()),axis=1).rename(\"tight3\")\n",
    "tightest_5_thrs = fdr_level_counts[5,\"U2OS_WT\"].apply(lambda x: x.idxmin(x.notna()),axis=1).rename(\"tight5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t3_all_counts = tightest_3_thrs.loc[lambda x: x.notna()].groupby(\"jaspar_id\").apply(lambda x: out.T.loc[idx[:, :, x.values[0]],x.name]).T\n",
    "# t5_all_counts = tightest_5_thrs.loc[lambda x: x.notna()].groupby(\"jaspar_id\").apply(lambda x: out.T.loc[idx[:, :, x.values[0]],x.name]).T\n",
    "                                                                                  \n",
    "                                                                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# enrichments = pd.concat([\n",
    "#     (t3_all_counts.reset_index().loc[lambda x: x.filter_color == 3].groupby([\"jaspar_id\",\"exp_type\"]).tight3.sum() /\\\n",
    "#    t3_all_counts.reset_index().groupby([\"jaspar_id\",\"exp_type\"]).tight3.sum()).rename(\"motif_3_enrichments\"),\n",
    "#     (t5_all_counts.reset_index().loc[lambda x: x.filter_color == 5].groupby([\"jaspar_id\",\"exp_type\"]).tight5.sum() /\\\n",
    "#    t5_all_counts.reset_index().groupby([\"jaspar_id\",\"exp_type\"]).tight5.sum()).rename(\"motif_5_enrichments\"),\n",
    "#     t3_all_counts.reset_index().groupby([\"jaspar_id\",\"exp_type\"]).tight3.sum().rename(\"motif_thr3_total_count\"),\n",
    "#     t5_all_counts.reset_index().groupby([\"jaspar_id\",\"exp_type\"]).tight5.sum().rename(\"motif_thr5_total_count\"),\n",
    "#     ],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(x = \"motif_3_enrichments\",y=\"motif_5_enrichments\",size = enrichments.reset_index().apply(lambda x:5 if x.motif_thr3_total_count>5 else 2,axis=1), \n",
    "#                 data = enrichments.reset_index().groupby(\"jaspar_id\").mean().fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each of the motifs selected, what are the enrichments on a per-base rate in differentially expressed (1+3) & (4+5) quantiles vs all oligos.  ###\n",
    "Having computed sets of candidate activator and repressor motifs in addition to recommded score thresholds for each motif in the steps above, we ask the question of how frequent is detection vs random occurence rate for (1) tight_3 threshold, (2) fpr_005 threshold, (3) threshold_patser. In each case, the number which is return will be a fraction of the motifs which are identified in that threshold within the (1+3) quantiles vs all positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_oligos = oligos.starts.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_quantile= .95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_oligo_counts_by_exp = quantiles.loc[lambda x: x[\"quantile\"] == base_quantile].groupby([\"exp_type\", \"filter_color\"]).size()\n",
    "n_activated = colored_oligo_counts_by_exp.groupby(\"exp_type\").apply(lambda x: (x.loc[1] if x.index.contains(1) else 0)+(x.loc[3] if 3 in x.index else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_activated = colored_oligo_counts_by_exp.unstack(\"filter_color\")[1] + colored_oligo_counts_by_exp.unstack(\"filter_color\")[3]\n",
    "n_repressed = colored_oligo_counts_by_exp.unstack(\"filter_color\")[4] + colored_oligo_counts_by_exp.unstack(\"filter_color\")[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_activated = n_activated / n_total_oligos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activator_motif_hits = motif_hits_of_interest.drop_duplicates([\"jaspar_id\",\"position\"]).set_index([\"jaspar_id\",\"position\"]).loc[pd.Index(jaspar_fdrs.index)].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tightest_3_thrs = fdr_level_counts[3,\"U2OS_WT\"].apply(lambda x: x.idxmin(x.notna()),axis=1).rename(\"tight3\")\n",
    "tightest_5_thrs = fdr_level_counts[5,\"U2OS_WT\"].apply(lambda x: x.idxmin(x.notna()),axis=1).rename(\"tight5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_quantile_hits = qjoin_afs.loc[lambda x:( x[\"quantile\"]==base_quantile)].set_index([\"exp_type\", \"jaspar_id\", \"mutant_start_position\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activator_motif_hits.reset_index().jaspar_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mageck_cis_regulatory_regions = pd.read_csv(\"../data/20190702_MaGeCK_LFC_gRNA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = \"start\",y = \"DLD1_rep3_LFC\", data= mageck_cis_regulatory_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repressor_names =  jaspar.loc[repressor_ids].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activator_names = jaspar.loc[activator_ids].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tight_3_score_thresholds = jaspar_fdrs.apply(lambda x : x.loc[tightest_3_thrs.loc[x.name]] if x.name in tightest_3_thrs.dropna().index else None, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tightest_3_thrs = fdr_level_counts[3,\"U2OS_WT\"].apply(lambda x: x.idxmin(x.notna()),axis=1).rename(\"tight3\")\n",
    "tightest_5_thrs = fdr_level_counts[5,\"U2OS_WT\"].apply(lambda x: x.idxmin(x.notna()),axis=1).rename(\"tight5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out =  jaspar_fdrs.apply( lambda j: j.apply(\n",
    "#     lambda f:\n",
    "# motif_hits_by_jid_start.loc[j.name].loc[lambda x:x.score > f].join(quantiles_u2os, on =\"target_mutant_start_position\",how=\"inner\")\\\n",
    "#                 .loc[lambda q:(q[\"quantile\"]==base_quantile) ].loc[lambda df:~df.index.duplicated()].groupby(\"filter_color\").size()).stack(\"filter_color\"),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaspar_fdrs.apply( \n",
    "#     lambda j: j.apply(\n",
    "#         lambda f:motif_hits_by_jid_start.loc[j.name].loc[lambda x:x.score > f].join(quantiles_u2os, on =\"target_mutant_start_position\",how=\"inner\")\\\n",
    "#                 .loc[lambda q:(q[\"quantile\"]==base_quantile) ].loc[lambda df:~df.index.duplicated()].groupby(\"filter_color\").size()),axis=1).iloc[:5]\n",
    "\n",
    "# motif_hits_by_jid_start.loc[j.name.loc[lambda x:x.score > f].join(quantiles_u2os, on =\"target_mutant_start_position\",how=\"inner\")\\\n",
    "#     .loc[lambda q:(q[\"quantile\"]==base_quantile) ].loc[lambda df:~df.index.duplicated()].groupby(\"filter_color\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOTIF ANALYSIS #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHICH MOTIFS ARE FOUND IN REGIONS OF DIFFERENTIAL EXPRESSION BETWEEN WILD-TYPE CELLS? ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs are found in regions of differential expression between WT & perturbed cell types? ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do enhancer regions exhibit differential activity in chemical perturbations of the cell types under study? \n",
    "\n",
    "We examined the same discrepancy measure in the context of cellular perturbations of U2OS and HCT116 cells. \n",
    "\n",
    "First, considering U2OS cells with NFKB1 and NFKB2 knockouts, we created the differential expression sets in the same manner as defined above and found [XXX] enhancer regions to exhibit differential expression activation “NFKB-enhancers”, including [XXX] enhancers with ranksort values which changed by more than 3 STANDARD DEVIATIONS. Sorting these cells to look at only GFP negative cells, we found [XXX] enhancers with ranksort values which changed by 3 STANDARD DEVIATIONS.\n",
    "\n",
    "Next, considering HCT116 cells subjected to treatment with 2uM gemtabicine, we found [XXX] enhancer regions exhibiting differential expression “GEMTAB-enhancers”. Amongst these, [XXX] of the enhancer regions had a ranksort difference of 3 STANDARD DEVIATIONS. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCT116_perturbation_on =pd.Series(True, index =  diffex.loc[lambda x: (x.expressed==\"HCT116_WT\") & (x.unexpressed==\"HCT116_GEM\")].oligo).rename(\"HCT116_perturbed_off\")\n",
    "HCT116_perturbation_off =  pd.Series(True, index = diffex.loc[lambda x: (x.expressed==\"HCT116_GEM\") & (x.unexpressed==\"HCT116_WT\")].oligo).rename(\"HCT116_perturbed_on\")\n",
    "U2OS_knockout_on = pd.Series(True, index =   diffex.loc[lambda x: (x.expressed==\"U2OS_WT\") & (x.unexpressed==\"U2OS_NFKB\")].oligo).rename(\"U2OS_perturbed_off\")\n",
    "U2OS_knockout_off =  pd.Series(True, index= diffex.loc[lambda x: (x.expressed==\"U2OS_NFKB\") & (x.unexpressed==\"U2OS_WT\")].oligo).rename(\"USOS_perturbed_on\")\n",
    "perturbations = pd.concat([HCT116_perturbation_off,HCT116_perturbation_on,U2OS_knockout_off,U2OS_knockout_on],axis=1)\n",
    "affine_score_threshold = 1\n",
    "jaspar_perturbation_hits = perturbations.apply(lambda x: motif_oligos_data.loc[lambda x: x.affine_score >affine_score_threshold].groupby(\"jaspar_id\").apply(lambda g:len(g.join(x.dropna(),on = \"oligo\",how =\"inner\").oligo.unique()))).reset_index()\n",
    "jaspar_perturbation_fracs = perturbations.apply(lambda p: motif_oligos_data.loc[lambda df: df.affine_score >affine_score_threshold].groupby(\"jaspar_id\").apply(lambda g:len(g.join(p.dropna(),on = \"oligo\",how =\"inner\").oligo.unique())/(g.oligo.nunique()*len(p.dropna())))).reset_index()\n",
    "jaspar_perturbation_fracs_unstacked = jaspar_perturbation_fracs.melt(id_vars = \"jaspar_id\", value_name =\"hit_frac\",var_name=\"perturbation_type\")\n",
    "sns.scatterplot(x=\"jaspar_id\",y=\"hit_frac\", hue=\"perturbation_type\", data = jaspar_perturbation_fracs_unstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOTIF DISCOVERY #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs do we discover in the unfiltered intervals ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "root = ET.parse('/Users/ben/src/meme-5.0.5/meme_out_2200/meme.xml').getroot()\n",
    "#arrays = [[[{e.attrib[\"letter_id\"]: e.text} for e in v if e.attrib[\"letter_id\"] in \"ATGC\"] for v in c[1].getchildren()[0].getchildren()] for c in root.getchildren()[2].getchildren()]\n",
    "arrays = [[dict([[e.attrib[\"letter_id\"],np.round( float(e.text) * 100)] for e in v if e.attrib[\"letter_id\"] in \"ATGC\"]) for v in c[1].getchildren()[0].getchildren()] for c in root.getchildren()[2].getchildren()]\n",
    "\n",
    "from Bio.motifs import jaspar\n",
    "import io\n",
    "import Bio\n",
    "from Bio.Alphabet import IUPAC\n",
    "motifs_string = \"\\n\".join([\">TEST{0} {0}\\n\".format(i) + \"\\n\".join([k + \" [\"+\" \".join([str(int(d[k])) for d in positions] ) +\"]\" for k in \"ATGC\"]) \n",
    "     for i, positions in enumerate(arrays)])\n",
    "f = io.StringIO(motifs_string)\n",
    "meme_motifs = jaspar.read(f,\"jaspar\")\n",
    "intervals[\"bioseq\"] = intervals.seq.apply(lambda x: Bio.Seq.Seq(x,alphabet = Bio.Alphabet.IUPAC.IUPACUnambiguousDNA()))\n",
    "\n",
    "for mm in meme_motifs: mm.pseudocounts = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which motifs do we discover in the expressed oligos? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[TODO] run meme on the expressed oligos only, using the negative null set as the background control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do the set of discovered motifs compare to the reference set? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaspar = z2_save_jaspar.load_jaspar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes =pd.Series(meme_motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaspar_array = np.array(list(e for e in jaspar.pwm.apply(lambda x: [e for k in \"ATGC\" for e in list(x[k])+([0]*(25 - len(x[k])))]).values))\n",
    "memes_array = np.array(list(e for e in memes.apply(lambda x: [e for k in \"ATGC\" for e in list(x.pwm[k])+([0]*(25 - len(x.pwm[k])))]).values))\n",
    "sns.clustermap(np.matmul( (jaspar_array / jaspar_array.sum(axis=1)[:,np.newaxis]),(memes_array/memes_array.sum(axis=1)[:,np.newaxis]).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_hits = memes.apply(lambda mm: intervals.apply(lambda x:[ e for e in  mm.pssm.search(x.bioseq)] , axis = 1))\n",
    "meme_unstacked =pd.concat(\n",
    "    [meme_hits.stack().groupby(level=[0,1]).apply(lambda g: pd.Series([e[0] for r in g for e in r])).rename(\"instance_idx\"),\n",
    "     meme_hits.stack().groupby(level=[0,1]).apply(lambda g: pd.Series([e[1] for r in g for e in r])).rename(\"instance_score\")]\n",
    "    ,axis = 1)\n",
    "\n",
    "meme_unstacked.index.levels[0].name=\"meme_motif\"\n",
    "meme_unstacked.index.levels[1].name=\"interval_id\"\n",
    "meme_unstacked = meme_unstacked.reset_index(level=[\"meme_motif\",\"interval_id\"]).reset_index(drop = True)\n",
    "meme_unstacked = meme_unstacked.join(memes.apply(lambda x:str(x.consensus)).rename(\"consensus\"),on = \"meme_motif\")\n",
    "meme_unstacked = meme_unstacked.join(intervals[[\"start\",\"end\",\"seq\"]], on = \"interval_id\")\n",
    "meme_unstacked[\"instance_position\"] = meme_unstacked.apply(\n",
    "    lambda x:x.start + x.instance_idx if x.instance_idx >= 0 else x.end + x.instance_idx,axis =1)\n",
    "meme_unstacked[\"instance_seq\"] = meme_unstacked.apply(lambda x:x.seq[x.instance_position - x.start:][:len(x.consensus)], axis = 1)\n",
    "\n",
    "#LOADS BIOLOGICAL MOTIFS AND SCANS ALL SUBREGIONS FOR OCCURENCES\n",
    "from pyfaidx import Fasta\n",
    "sequences_fa = Fasta('/Users/ben/genomes/GRCh38.primary_assembly.genome.fa')\n",
    "chrseq = str(sequences_fa[\"chr22\"])\n",
    "region_bounds=[ 38699734, 39291007]\n",
    "background = dict([[l,chrseq[region_bounds[0]:region_bounds[1]].count(l) / len(chrseq[region_bounds[0]:region_bounds[1]])] for l in \"ATGC\"])\n",
    "\n",
    "memes_patser = memes.apply(lambda x: x.pssm.distribution(background=background, precision=10**3).threshold_patser())\n",
    "meme_unstacked = meme_unstacked.join(memes_patser.rename(\"motif_threshold_patser\"),on=\"meme_motif\")\n",
    "meme_unstacked[\"affine_score\"] = meme_unstacked[\"instance_score\"] - meme_unstacked[\"motif_threshold_patser\"]\n",
    "meme_unstacked[\"instance_identity\"] = meme_unstacked[[\"instance_seq\",\"consensus\"]].apply(lambda x: float(len([ i for i,l in enumerate(x.instance_seq) if l == x.consensus[i]]))/len(x.consensus),axis=1)\n",
    "\n",
    "\n",
    "sns.scatterplot( x = \"instance_identity\", y = \"affine_score\", data= meme_unstacked)\n",
    "plt.figure()\n",
    "sns.scatterplot( x = \"meme_motif\", y = \"affine_score\", data= meme_unstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Lin ##\n",
    "1. A list of the most statistically enrich \"activators\" -- Does this mean \"regions\"? or motifs?\n",
    "2. Currently working on a small molecule experiment which inhibits FOSL1, [...?]\n",
    "3. A list of the most enriched subregions, putting emphasis on finding one which is highly enriched, but does not identify a fold-change repressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEVEL_DIFFERENT_CANDIDATES = motif_filter_color_counts.reset_index().\\\n",
    "    loc[lambda df: df.exp_type.isin([\"U2OS_WT\",\"U2OS_NFKB\",\"HCT116_WT\",\"HCT116_GEM\",\"DLD1_WT\"])].\\\n",
    "    loc[lambda df: (df[\"quantile\"] == .75) & (df[\"affine_score_threshold\"] == 2)  & (df[\"filter_color\"] == 1)]\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEVEL_DIFFERENT_TABLE = LEVEL_DIFFERENT_CANDIDATES.set_index([\"exp_type\",\"jaspar_id\"]).color_1_enrichment.unstack().T.join(jaspar.name).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL_DIFFERENT_TABLE = LEVEL_DIFFERENT_CANDIDATES.unstack(\"exp_type\")[\"color_3_enrichment\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEM_MOTIFS = (LEVEL_DIFFERENT_TABLE.HCT116_GEM - LEVEL_DIFFERENT_TABLE.HCT116_WT).loc[lambda x: x> 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(motif_hits_of_interest.set_index(\"jaspar_id\").loc[lambda x: (x.score > (x.threshold_fdr_005)) & (x.score > (x.threshold_patser))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(motif_hits_of_interest.set_index(\"jaspar_id\").loc[lambda x: (x.score > (x.threshold_fdr_005 -1)) & (x.score > (x.threshold_patser-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEM_MOTIFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oligos_of_interest = GEM_MOTIFS.to_frame().join(\n",
    "    motif_hits_of_interest.set_index(\"jaspar_id\").loc[lambda x: (x.score > (x.threshold_fdr_005 )) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oligos_with_experiments = \\\n",
    "    oligos_of_interest.reset_index()[[\"jaspar_id\",\"oligo\",\"score\",\"threshold_fdr_005\"]].join(oligos_by_exp.set_index(\"oligo\"),on=\"oligo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_scoring_owe = oligos_with_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_expressions = oligos_by_exp.groupby(\"exp_type\").mu.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_scoring_owe.groupby([\"jaspar_id\",\"exp_type\"]).mu.mean().unstack() / norm_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(region_bounds[0],region_bounds[1],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "these_motifs = motif_hits_of_interest.loc[lambda x: x.jaspar_id == 31].drop_duplicates([\"jaspar_id\",\"position\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_expression_by_exp = oligos_by_exp.groupby(\"exp_type\").mu.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_expression_by_exp_nm = oligos_by_exp.groupby(\"exp_nm\").mu.mean()\n",
    "mean_stds_by_exp_nm = oligos_by_exp.groupby(\"exp_nm\").mu.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_means_by_nm =  jaspar.apply(lambda j: \n",
    "    (oligos_by_exp.loc[lambda x: (x.oligo.isin(\\\n",
    "                                              motif_hits_of_interest.loc[lambda x: x.jaspar_id == j.name].oligo\\\n",
    "                                                 )) & x.oligo.isin(wt_oligos.index)].groupby(\"exp_nm\").mu.mean() - mean_expression_by_exp_nm)/mean_stds_by_exp_nm,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out_stds_by_nm = jaspar.apply(lambda j: \n",
    "    oligos_by_exp.loc[lambda x: (x.oligo.isin(\\\n",
    "                                              motif_hits_of_interest.loc[lambda x: x.jaspar_id == j.name].oligo\\\n",
    "                                                 )) & x.oligo.isin(wt_oligos.index)].groupby(\"exp_nm\").mu.std()/mean_stds_by_exp_nm,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_means_by_nm.columns.name = \"exp_nm\"\n",
    "out_stds_by_nm.columns.name = \"exp_nm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_outval = (out_means_by_nm.U2OS_WT - out_means_by_nm.U2OS_NFKB2KO_Sorted_GFPneg) / (out_stds_by_nm.U2OS_WT + out_stds_by_nm.U2OS_NFKB2KO_Sorted_GFPneg)*2\n",
    "\n",
    "\n",
    "with_sort = out_means_by_nm.reset_index().sort_values(\"U2OS_WT\").reset_index(drop=True).reset_index().set_index(\"jaspar_id\")\n",
    "\n",
    "bins = np.linspace(-2,2,200)\n",
    "plt.hist(new_outval,bins = bins)\n",
    "plt.gca().set_title(\"z-score distribution of expression level changes between GEM & HCT WT\")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "f, subs = plt.subplots(1,2)\n",
    "f = plt.gcf()\n",
    "f.set_size_inches(16,6)\n",
    "plt.sca(subs[0])\n",
    "sns.lineplot(x=\"index\",y=\"value\", hue=\"exp_nm\", data = with_sort.reset_index().melt(id_vars=[\"jaspar_id\",\"index\"]).loc[lambda x: x.exp_nm.str.contains(\"U2OS\")])\n",
    "\n",
    "plt.sca(subs[1])\n",
    "\n",
    "with_sort2 = out_means_by_nm.reset_index().sort_values(\"U2OS_WT\").reset_index(drop=True).reset_index().set_index(\"jaspar_id\")\n",
    "sns.lineplot(x=\"index\",y=\"value\", hue=\"exp_nm\", data = with_sort2.reset_index().melt(id_vars=[\"jaspar_id\",\"index\"]).loc[lambda x: x.exp_nm.str.contains(\"U2OS\")])\n",
    "\n",
    "\n",
    "LIN_DIFFERENTIAL_U2OSWT_VS_NFKB2_EXPRESSION_ZSCORES = new_outval.rename(\"zscore_wt_minus_neg\").to_frame().join(jaspar)[[\"name\",\"consensus\",\"zscore_wt_minus_neg\"]]\\\n",
    "    .join(out_means_by_nm[[\"U2OS_WT\",\"U2OS_NFKB2KO_Sorted_GFPneg\"]].rename(lambda x: x+\"_MEAN\",axis=\"columns\"))\\\n",
    "    .join(out_stds_by_nm[[\"U2OS_WT\",\"U2OS_NFKB2KO_Sorted_GFPneg\"]].rename(lambda x: x+\"_STD\",axis=\"columns\"))\n",
    "\n",
    "LIN_DIFFERENTIAL_U2OSWT_VS_NFKB2_EXPRESSION_ZSCORES.to_csv(\"../data/0808_LIN_DIFFERENTIAL_U2OSWT_VS_NFKB2_EXPRESSION_ZSCORES.csv\")\n",
    "\n",
    "new_outval = (out_means_by_nm.U2OS_NFKB2KO_Sorted_GFPneg - out_means_by_nm.U2OS_NFKB2KO_Sorted_GFPpos) / (out_stds_by_nm.U2OS_NFKB2KO_Sorted_GFPpos + out_stds_by_nm.U2OS_NFKB2KO_Sorted_GFPneg)*2\n",
    "\n",
    "\n",
    "with_sort = out_means_by_nm.reset_index().sort_values(\"U2OS_NFKB2KO_Sorted_GFPneg\").reset_index(drop=True).reset_index().set_index(\"jaspar_id\")\n",
    "\n",
    "bins = np.linspace(-2,2,200)\n",
    "plt.hist(new_outval,bins = bins)\n",
    "plt.gca().set_title(\"z-score distribution of expression level changes between GEM & HCT WT\")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "f, subs = plt.subplots(1,2)\n",
    "f = plt.gcf()\n",
    "f.set_size_inches(16,6)\n",
    "plt.sca(subs[0])\n",
    "sns.lineplot(x=\"index\",y=\"value\", hue=\"exp_nm\", data = with_sort.reset_index().melt(id_vars=[\"jaspar_id\",\"index\"]).loc[lambda x: x.exp_nm.str.contains(\"U2OS\")])\n",
    "\n",
    "plt.sca(subs[1])\n",
    "\n",
    "with_sort2 = out_means_by_nm.reset_index().sort_values(\"U2OS_NFKB2KO_Sorted_GFPneg\").reset_index(drop=True).reset_index().set_index(\"jaspar_id\")\n",
    "sns.lineplot(x=\"index\",y=\"value\", hue=\"exp_nm\", data = with_sort2.reset_index().melt(id_vars=[\"jaspar_id\",\"index\"]).loc[lambda x: x.exp_nm.str.contains(\"U2OS\")])\n",
    "\n",
    "LIN_DIFFERENTIAL_U2OS_NFKB2_PLUS_VS_NFKB2_MINUS_EXPRESSION_ZSCORES = new_outval.rename(\"zscore_neg_minus_pos\").to_frame().join(jaspar)[[\"name\",\"consensus\",\"zscore_neg_minus_pos\"]]\\\n",
    "    .join(out_means_by_nm[[\"U2OS_NFKB2KO_Sorted_GFPpos\",\"U2OS_NFKB2KO_Sorted_GFPneg\"]].rename(lambda x: x+\"_MEAN\",axis=\"columns\"))\\\n",
    "    .join(out_stds_by_nm[[\"U2OS_NFKB2KO_Sorted_GFPpos\",\"U2OS_NFKB2KO_Sorted_GFPneg\"]].rename(lambda x: x+\"_STD\",axis=\"columns\"))\n",
    "\n",
    "LIN_DIFFERENTIAL_U2OS_NFKB2_PLUS_VS_NFKB2_MINUS_EXPRESSION_ZSCORES.to_csv(\"../data/0808_LIN_DIFFERENTIAL_U2OS_NFKB2_PLUS_VS_NFKB2_MINUS_EXPRESSION_ZSCORES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_outval = (out_means_by_nm.U2OS_WT - out_means_by_nm.U2OS_NFKB1KO_Sorted_GFPneg) / (out_stds_by_nm.U2OS_WT + out_stds_by_nm.U2OS_NFKB1KO_Sorted_GFPneg)*2\n",
    "\n",
    "\n",
    "with_sort = out_means_by_nm.reset_index().sort_values(\"U2OS_WT\").reset_index(drop=True).reset_index().set_index(\"jaspar_id\")\n",
    "\n",
    "bins = np.linspace(-2,2,200)\n",
    "plt.hist(new_outval,bins = bins)\n",
    "plt.gca().set_title(\"z-score distribution of expression level changes between GEM & HCT WT\")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "f, subs = plt.subplots(1,2)\n",
    "f = plt.gcf()\n",
    "f.set_size_inches(16,6)\n",
    "plt.sca(subs[0])\n",
    "sns.lineplot(x=\"index\",y=\"value\", hue=\"exp_nm\", data = with_sort.reset_index().melt(id_vars=[\"jaspar_id\",\"index\"]).loc[lambda x: x.exp_nm.str.contains(\"U2OS\")])\n",
    "\n",
    "plt.sca(subs[1])\n",
    "\n",
    "with_sort2 = out_means_by_nm.reset_index().sort_values(\"U2OS_WT\").reset_index(drop=True).reset_index().set_index(\"jaspar_id\")\n",
    "sns.lineplot(x=\"index\",y=\"value\", hue=\"exp_nm\", data = with_sort2.reset_index().melt(id_vars=[\"jaspar_id\",\"index\"]).loc[lambda x: x.exp_nm.str.contains(\"U2OS\")])\n",
    "\n",
    "\n",
    "LIN_DIFFERENTIAL_U2OSWT_VS_NFKB1_EXPRESSION_ZSCORES = new_outval.rename(\"zscore_wt_minus_neg\").to_frame().join(jaspar)[[\"name\",\"consensus\",\"zscore_wt_minus_neg\"]]\\\n",
    "    .join(out_means_by_nm[[\"U2OS_WT\",\"U2OS_NFKB1KO_Sorted_GFPneg\"]].rename(lambda x: x+\"_MEAN\",axis=\"columns\"))\\\n",
    "    .join(out_stds_by_nm[[\"U2OS_WT\",\"U2OS_NFKB1KO_Sorted_GFPneg\"]].rename(lambda x: x+\"_STD\",axis=\"columns\"))\n",
    "\n",
    "LIN_DIFFERENTIAL_U2OSWT_VS_NFKB1_EXPRESSION_ZSCORES.to_csv(\"../data/0808_LIN_DIFFERENTIAL_U2OSWT_VS_NFKB1_EXPRESSION_ZSCORES.csv\")\n",
    "\n",
    "new_outval = (out_means_by_nm.U2OS_NFKB1KO_Sorted_GFPneg - out_means_by_nm.U2OS_NFKB1KO_Sorted_GFPpos) / (out_stds_by_nm.U2OS_NFKB1KO_Sorted_GFPpos + out_stds_by_nm.U2OS_NFKB1KO_Sorted_GFPneg)*2\n",
    "\n",
    "\n",
    "with_sort = out_means_by_nm.reset_index().sort_values(\"U2OS_NFKB1KO_Sorted_GFPneg\").reset_index(drop=True).reset_index().set_index(\"jaspar_id\")\n",
    "\n",
    "bins = np.linspace(-2,2,200)\n",
    "plt.hist(new_outval,bins = bins)\n",
    "plt.gca().set_title(\"z-score distribution of expression level changes between GEM & HCT WT\")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "f, subs = plt.subplots(1,2)\n",
    "f = plt.gcf()\n",
    "f.set_size_inches(16,6)\n",
    "plt.sca(subs[0])\n",
    "sns.lineplot(x=\"index\",y=\"value\", hue=\"exp_nm\", data = with_sort.reset_index().melt(id_vars=[\"jaspar_id\",\"index\"]).loc[lambda x: x.exp_nm.str.contains(\"U2OS\")])\n",
    "\n",
    "plt.sca(subs[1])\n",
    "\n",
    "with_sort2 = out_means_by_nm.reset_index().sort_values(\"U2OS_NFKB1KO_Sorted_GFPneg\").reset_index(drop=True).reset_index().set_index(\"jaspar_id\")\n",
    "sns.lineplot(x=\"index\",y=\"value\", hue=\"exp_nm\", data = with_sort2.reset_index().melt(id_vars=[\"jaspar_id\",\"index\"]).loc[lambda x: x.exp_nm.str.contains(\"U2OS\")])\n",
    "\n",
    "LIN_DIFFERENTIAL_U2OS_NFKB1_PLUS_VS_NFKB1_MINUS_EXPRESSION_ZSCORES = new_outval.rename(\"zscore_neg_minus_pos\").to_frame().join(jaspar)[[\"name\",\"consensus\",\"zscore_neg_minus_pos\"]]\\\n",
    "    .join(out_means_by_nm[[\"U2OS_NFKB1KO_Sorted_GFPpos\",\"U2OS_NFKB1KO_Sorted_GFPneg\"]].rename(lambda x: x+\"_MEAN\",axis=\"columns\"))\\\n",
    "    .join(out_stds_by_nm[[\"U2OS_NFKB1KO_Sorted_GFPpos\",\"U2OS_NFKB1KO_Sorted_GFPneg\"]].rename(lambda x: x+\"_STD\",axis=\"columns\"))\n",
    "\n",
    "LIN_DIFFERENTIAL_U2OS_NFKB1_PLUS_VS_NFKB1_MINUS_EXPRESSION_ZSCORES.to_csv(\"../data/0808_LIN_DIFFERENTIAL_U2OS_NFKB1_PLUS_VS_NFKB1_MINUS_EXPRESSION_ZSCORES.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIN_DIFFERENTIAL_U2OS_NFKB2_PLUS_VS_NFKB2_MINUS_EXPRESSION_ZSCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_expressions_by_exp = oligos_by_exp.groupby(\"exp_type\").mu.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_means = jaspar.apply(lambda j: \n",
    "    (oligos_by_exp.loc[lambda x: (x.oligo.isin(\\\n",
    "                                              motif_hits_of_interest.loc[lambda x: x.jaspar_id == j.name].oligo\\\n",
    "                                                 )) & x.oligo.isin(wt_oligos.index)].groupby(\"exp_type\").mu.mean() - mean_expressions_by_exp)/std_expression_by_exp,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out_stds = jaspar.apply(lambda j: \n",
    "    oligos_by_exp.loc[lambda x: (x.oligo.isin(\\\n",
    "                                              motif_hits_of_interest.loc[lambda x: x.jaspar_id == j.name].oligo\\\n",
    "                                                 )) & x.oligo.isin(wt_oligos.index)].groupby(\"exp_type\").mu.std()/std_expression_by_exp ,axis=1)\n",
    "\n",
    "\n",
    "new_outval = (out_means.HCT116_GEM - out_means.HCT116_WT) / (out_stds.HCT116_GEM + out_stds.HCT116_WT)*2\n",
    "\n",
    "\n",
    "with_sort = out_means.reset_index().sort_values(\"HCT116_WT\").reset_index(drop=True).reset_index().set_index(\"jaspar_id\")\n",
    "\n",
    "bins = np.linspace(-2,2,200)\n",
    "plt.hist(new_outval,bins = bins)\n",
    "plt.gca().set_title(\"z-score distribution of expression level changes between GEM & HCT WT\")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "f, subs = plt.subplots(1,2)\n",
    "f = plt.gcf()\n",
    "f.set_size_inches(16,6)\n",
    "plt.sca(subs[0])\n",
    "sns.lineplot(x=\"index\",y=\"value\", hue=\"exp_type\", data = with_sort.reset_index().melt(id_vars=[\"jaspar_id\",\"index\"]).loc[lambda x: x.exp_type.str.contains(\"HCT\")])\n",
    "\n",
    "plt.sca(subs[1])\n",
    "\n",
    "with_sort2 = out_means.reset_index().sort_values(\"HCT116_GEM\").reset_index(drop=True).reset_index().set_index(\"jaspar_id\")\n",
    "sns.lineplot(x=\"index\",y=\"value\", hue=\"exp_type\", data = with_sort2.reset_index().melt(id_vars=[\"jaspar_id\",\"index\"]).loc[lambda x: x.exp_type.str.contains(\"HCT\")])\n",
    "\n",
    "\n",
    "LIN_HCT116_DIFFERENTIAL_EXPRESSION_ZSCORES = new_outval.rename(\"zscore\").to_frame().join(jaspar)[[\"name\",\"consensus\",\"zscore\"]]\\\n",
    "    .join(out_means[[\"HCT116_GEM\",\"HCT116_WT\"]].rename(lambda x: x+\"_MEAN\",axis=\"columns\"))\\\n",
    "    .join(out_stds[[\"HCT116_GEM\",\"HCT116_WT\"]].rename(lambda x: x+\"_STD\",axis=\"columns\"))\n",
    "\n",
    "LIN_HCT116_DIFFERENTIAL_EXPRESSION_ZSCORES.to_csv(\"../data/0808_LIN_HCT116_DIFFERENTIAL_EXPRESSION_ZSCORES.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX #\n",
    "Additional figureds which may be useful in understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPENDIX A: RANKSORT DISCREPANCIES ###\n",
    "The selection of APOBEC-differential-activators was performed based on a change in the ranksorted expression levels between the two APOBEC expressing cell types under study. For this to be a valid measure, we would hope that the majority of activators were discovered in both cell types and that their differences fell under the differential expression threshold. \n",
    "\n",
    "This is the case to a limited extent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f,subs = plt.subplots(2,2)\n",
    "f.set_size_inches(7,7)\n",
    "plt.sca(subs[0][0])\n",
    "sns.scatterplot(obe.U2OS_WT_rank,obe.DLD1_WT_rank)\n",
    "\n",
    "plt.sca(subs[0][1])\n",
    "\n",
    "sns.scatterplot(\n",
    "    x = \"U2OS_WT_rank\",\n",
    "    y = \"DLD1_WT_rank\",\n",
    "    data =  obe.loc[lambda x: x.oligo.isin(ABon_ids)],\n",
    ")\n",
    "plt.gca().set_title(f\"rank of {len(ABon_ids)} ABex oligo ranks\")\n",
    "\n",
    "\n",
    "plt.sca(subs[1][0])\n",
    "sns.scatterplot(\n",
    "    x = \"U2OS_WT_rank\",\n",
    "    y = \"DLD1_WT_rank\",\n",
    "    data =  obe.loc[lambda x: x.oligo.isin(U2on_ids)],\n",
    ")\n",
    "plt.gca().set_title(f\"rank of {len(U2on_ids)} U2on oligo ranks\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gca().set_xlim([0,200])\n",
    "plt.gca().set_ylim([0,200])\n",
    "\n",
    "\n",
    "plt.sca(subs[1][1])\n",
    "sns.scatterplot(\n",
    "    x = \"U2OS_WT_rank\",\n",
    "    y = \"U2OS_NFKB_rank\",\n",
    "    data =  obe.loc[lambda x: x.oligo.isin(U2on_ids)],\n",
    ")\n",
    "plt.gca().set_title(f\"rank of {len(U2on_ids)} ABon oligo ranks\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gca().set_xlim([0,200])\n",
    "plt.gca().set_ylim([0,200])\n",
    "\n",
    "f = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_title (\"histogram of rank change differenes between DLD1 and U2OS\\n expression levels for all oligos in APOBEC-sometimes\")\n",
    "\n",
    "plt.hist(  (obe.loc[lambda x:x.oligo.isin(ABst_ids)].DLD1_WT_rank - \n",
    "            obe.loc[lambda x:x.oligo.isin(ABst_ids)].U2OS_WT_rank ).abs() ,\n",
    "        bins = np.arange(0,1000,50))\n",
    "\n",
    "f = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_title (\"histogram of rank change differenes between DLD1 and U2OS\\n expression levels for all oligos\")\n",
    "\n",
    "plt.hist(  (obe.DLD1_WT_rank - obe.U2OS_WT_rank ).abs(),\n",
    "         bins = np.arange(0,1000,50) )\n",
    "\n",
    "\n",
    "# obe_win = obe.loc[lambda x: x.oligo.isin(U2on_ids)]\n",
    "# from scipy import stats\n",
    "# def r2(x, y):\n",
    "#     return stats.pearsonr(x, y)[0] ** 2\n",
    "\n",
    "# def pval(x, y):\n",
    "#     return stats.pearsonr(x, y)[1] ** 2\n",
    "\n",
    "# sns.jointplot(\"U2OS_WT_rank\",\"DLD1_WT_rank\", kind=\"reg\", stat_func=r2,data = obe_win)\n",
    "# #sns.regplot(\"U2OS_WT_rank\",\"DLD1_WT_rank\",data = obe_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_activator_oligos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thr = 2\n",
    "color3 = motif_filter_color_counts.reset_index()\\\n",
    "    .loc[lambda x:(x[\"quantile\"] ==.9) & (x[\"affine_score_threshold\"] == thr) &  (x[\"color_3_enrichment\"] >0 ) ]\n",
    "\n",
    "U2_oligos =pd.concat( [\n",
    "                       pd.Series(\"activator\",index = EXP_activator_oligos.loc[\"U2OS_WT\"].oligo),\n",
    "pd.Series(\"repressor\",index = EXP_repressor_oligos.loc[\"U2OS_WT\"].oligo),\n",
    "    pd.Series(\"null\",index = EXP_null_oligos.loc[\"U2OS_WT\"].oligo)\n",
    "],axis = 0).rename(\"otype\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#APPENDIX: U2OS CELL TYPE ANALYSIS OF ENRICHMENTS\n",
    "oligo_types = U2_oligos.to_frame().set_index(\"otype\",append=True).assign(val=1).reset_index().pivot_table(index=\"oligo\",columns=\"otype\")[\"val\"].fillna(0)\n",
    "modata_thr = motif_oligos_data.loc[lambda x:(x.affine_score > thr) & (x.is_overlapping_wt)].set_index(\"jaspar_id\").sort_index()\n",
    "motif_wt_oligo_counts = jaspar.reset_index().apply(lambda x: len(modata_thr.loc[x.jaspar_id]) if x.jaspar_id in modata_thr.index.get_level_values(0) else 0,axis =1)\n",
    "\n",
    "oligo_type_counts =  modata_thr.groupby(\"jaspar_id\").apply(lambda g1:\n",
    "oligo_types.apply( \n",
    "    lambda y:\n",
    "y.loc[[e for e in g1.oligo.unique() if e in y.index]].sum()\n",
    "))\n",
    "oligo_type_fracs = oligo_type_counts.apply(lambda x: x / x.sum(), axis =1).fillna(0) / oligo_type_counts.mean(axis=0)\n",
    "color_counts_2d = (motif_filter_color_counts.reset_index()\\\n",
    "    .loc[lambda x:(x[\"quantile\"] ==.95) & (x[\"affine_score_threshold\"] == 1) ]\\\n",
    "    .groupby([\"jaspar_id\",\"exp_type\"]).apply(lambda x: x.color_2_enrichment.max()+x.color_3_enrichment.max()).unstack() ) * 1 \n",
    "color_counts_2d = color_counts_2d /color_counts_2d.mean(axis=0)\n",
    "\n",
    "plt.gcf().set_size_inches(12,3)\n",
    "plt.gca().set_title(\"which motifs meet the\")\n",
    "sns.heatmap(pd.concat([color_counts_2d, oligo_type_fracs[[\"activator\",\"null\",\"repressor\"]]],axis = 1).fillna(0).T>0,square=True,cbar=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
